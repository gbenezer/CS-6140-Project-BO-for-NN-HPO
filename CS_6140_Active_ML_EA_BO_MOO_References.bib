
@article{zhang_active_2023,
	title = {Active learning for optimal intervention design in causal models},
	volume = {5},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-023-00719-0},
	doi = {10.1038/s42256-023-00719-0},
	language = {en},
	number = {10},
	urldate = {2025-02-02},
	journal = {Nature Machine Intelligence},
	author = {Zhang, Jiaqi and Cammarata, Louis and Squires, Chandler and Sapsis, Themistoklis P. and Uhler, Caroline},
	month = oct,
	year = {2023},
	pages = {1066--1075},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\V7KIE7QT\\Zhang et al. - 2023 - Active learning for optimal intervention design in causal models.pdf:application/pdf},
}

@misc{zhang_uhlerlabactlearn_optint_2023,
	title = {uhlerlab/actlearn\_optint: v1},
	shorttitle = {uhlerlab/actlearn\_optint},
	url = {https://zenodo.org/records/8170179},
	abstract = {Active learning for optimal intervention design in causal models},
	urldate = {2025-02-02},
	publisher = {Zenodo},
	author = {Zhang, Jiaqi},
	month = jul,
	year = {2023},
	doi = {10.5281/zenodo.8170179},
	file = {Snapshot:C\:\\Users\\Gil\\Zotero\\storage\\VW2WQHRK\\8170179.html:text/html},
}

@article{frangieh_multimodal_2021,
	title = {Multimodal pooled {Perturb}-{CITE}-seq screens in patient models define mechanisms of cancer immune evasion},
	volume = {53},
	issn = {1061-4036, 1546-1718},
	url = {https://www.nature.com/articles/s41588-021-00779-1},
	doi = {10.1038/s41588-021-00779-1},
	language = {en},
	number = {3},
	urldate = {2025-02-02},
	journal = {Nature Genetics},
	author = {Frangieh, Chris J. and Melms, Johannes C. and Thakore, Pratiksha I. and Geiger-Schuller, Kathryn R. and Ho, Patricia and Luoma, Adrienne M. and Cleary, Brian and Jerby-Arnon, Livnat and Malu, Shruti and Cuoco, Michael S. and Zhao, Maryann and Ager, Casey R. and Rogava, Meri and Hovey, Lila and Rotem, Asaf and Bernatchez, Chantale and Wucherpfennig, Kai W. and Johnson, Bruce E. and Rozenblatt-Rosen, Orit and Schadendorf, Dirk and Regev, Aviv and Izar, Benjamin},
	month = mar,
	year = {2021},
	pages = {332--341},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\HRPWEV4H\\Frangieh et al. - 2021 - Multimodal pooled Perturb-CITE-seq screens in patient models define mechanisms of cancer immune evas.pdf:application/pdf},
}

@article{fu_survey_2013,
	title = {A survey on instance selection for active learning},
	volume = {35},
	copyright = {http://www.springer.com/tdm},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-012-0507-8},
	doi = {10.1007/s10115-012-0507-8},
	abstract = {Active learning aims to train an accurate prediction model with minimum cost by labeling most informative instances. In this paper, we survey existing works on active learning from an instance-selection perspective and classify them into two categories with a progressive relationship: (1) active learning merely based on uncertainty of independent and identically distributed (IID) instances, and (2) active learning by further taking into account instance correlations. Using the above categorization, we summarize major approaches in the ﬁeld, along with their technical strengths/weaknesses, followed by a simple runtime performance comparison, and discussion about emerging active learning applications and instance-selection challenges therein. This survey intends to provide a high-level summarization for active learning and motivates interested readers to consider instance-selection approaches for designing effective active learning solutions.},
	language = {en},
	number = {2},
	urldate = {2025-02-02},
	journal = {Knowledge and Information Systems},
	author = {Fu, Yifan and Zhu, Xingquan and Li, Bin},
	month = may,
	year = {2013},
	pages = {249--283},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\IKMLWJ7Q\\Fu et al. - 2013 - A survey on instance selection for active learning.pdf:application/pdf},
}

@article{gevertz_minimally_2024,
	title = {Minimally sufficient experimental design using identifiability analysis},
	volume = {10},
	issn = {2056-7189},
	url = {https://www.nature.com/articles/s41540-023-00325-1},
	doi = {10.1038/s41540-023-00325-1},
	abstract = {Abstract
            Mathematical models are increasingly being developed and calibrated in tandem with data collection, empowering scientists to intervene in real time based on quantitative model predictions. Well-designed experiments can help augment the predictive power of a mathematical model but the question of when to collect data to maximize its utility for a model is non-trivial. Here we define data as model-informative if it results in a unique parametrization, assessed through the lens of practical identifiability. The framework we propose identifies an optimal experimental design (how much data to collect and when to collect it) that ensures parameter identifiability (permitting confidence in model predictions), while minimizing experimental time and costs. We demonstrate the power of the method by applying it to a modified version of a classic site-of-action pharmacokinetic/pharmacodynamic model that describes distribution of a drug into the tumor microenvironment (TME), where its efficacy is dependent on the level of target occupancy in the TME. In this context, we identify a minimal set of time points when data needs to be collected that robustly ensures practical identifiability of model parameters. The proposed methodology can be applied broadly to any mathematical model, allowing for the identification of a minimally sufficient experimental design that collects the most informative data.},
	language = {en},
	number = {1},
	urldate = {2025-02-02},
	journal = {npj Systems Biology and Applications},
	author = {Gevertz, Jana L. and Kareva, Irina},
	month = jan,
	year = {2024},
	pages = {2},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\EEIZS76P\\Gevertz and Kareva - 2024 - Minimally sufficient experimental design using identifiability analysis.pdf:application/pdf},
}

@misc{houlsby_bayesian_2011,
	title = {Bayesian {Active} {Learning} for {Classification} and {Preference} {Learning}},
	url = {http://arxiv.org/abs/1112.5745},
	doi = {10.48550/arXiv.1112.5745},
	abstract = {Information theoretic active learning has been widely studied for probabilistic models. For simple regression an optimal myopic policy is easily tractable. However, for other tasks and with more complex models, such as classiﬁcation with nonparametric models, the optimal solution is harder to compute. Current approaches make approximations to achieve tractability. We propose an approach that expresses information gain in terms of predictive entropies, and apply this method to the Gaussian Process Classiﬁer (GPC). Our approach makes minimal approximations to the full information theoretic objective. Our experimental performance compares favourably to many popular active learning algorithms, and has equal or lower computational complexity. We compare well to decision theoretic approaches also, which are privy to more information and require much more computational time. Secondly, by developing further a reformulation of binary preference learning to a classiﬁcation problem, we extend our algorithm to Gaussian Process preference learning.},
	language = {en},
	urldate = {2025-02-02},
	publisher = {arXiv},
	author = {Houlsby, Neil and Huszár, Ferenc and Ghahramani, Zoubin and Lengyel, Máté},
	month = dec,
	year = {2011},
	note = {arXiv:1112.5745 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\3NNB4X3Z\\Houlsby et al. - 2011 - Bayesian Active Learning for Classification and Preference Learning.pdf:application/pdf},
}

@article{terayama_black-box_2021,
	title = {Black-{Box} {Optimization} for {Automated} {Discovery}},
	volume = {54},
	copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {0001-4842, 1520-4898},
	url = {https://pubs.acs.org/doi/10.1021/acs.accounts.0c00713},
	doi = {10.1021/acs.accounts.0c00713},
	language = {en},
	number = {6},
	urldate = {2025-02-02},
	journal = {Accounts of Chemical Research},
	author = {Terayama, Kei and Sumita, Masato and Tamura, Ryo and Tsuda, Koji},
	month = mar,
	year = {2021},
	pages = {1334--1346},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\AGJ25K46\\Terayama et al. - 2021 - Black-Box Optimization for Automated Discovery.pdf:application/pdf},
}

@inproceedings{malu_bayesian_2021,
	address = {Chania Crete, Greece},
	title = {Bayesian {Optimization} in {High}-{Dimensional} {Spaces}: {A} {Brief} {Survey}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-6654-0032-9},
	shorttitle = {Bayesian {Optimization} in {High}-{Dimensional} {Spaces}},
	url = {https://ieeexplore.ieee.org/document/9555522/},
	doi = {10.1109/IISA52424.2021.9555522},
	abstract = {Bayesian optimization (BO) has been widely applied to several modern science and engineering applications such as machine learning, neural networks, robotics, aerospace engineering, experimental design. BO has emerged as the modus operandi for global optimization of an arbitrary expensive to evaluate black box function f . Although BO has been very successful in low dimensions, scaling it to high dimensional spaces has been signiﬁcantly challenging due to its exponentially increasing statistical and computational complexity with increasing dimensions. In this era of high dimensional data where the input features are of million dimensions scaling BO to higher dimensions is one of the important goals in the ﬁeld. There has been a lot of work in recent years to scale BO to higher dimensions, in many of these methods some underlying structure on the objective function is exploited. In this paper, we review recent efforts in this area. In particular, we focus on the methods that exploit different underlying structures on the objective function to scale BO to high dimensions.},
	language = {en},
	urldate = {2025-02-02},
	booktitle = {2021 12th {International} {Conference} on {Information}, {Intelligence}, {Systems} \& {Applications} ({IISA})},
	publisher = {IEEE},
	author = {Malu, Mohit and Dasarathy, Gautam and Spanias, Andreas},
	month = jul,
	year = {2021},
	pages = {1--8},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\VUTX5ETA\\Malu et al. - 2021 - Bayesian Optimization in High-Dimensional Spaces A Brief Survey.pdf:application/pdf},
}

@article{greenhill_bayesian_2020,
	title = {Bayesian {Optimization} for {Adaptive} {Experimental} {Design}: {A} {Review}},
	volume = {8},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	shorttitle = {Bayesian {Optimization} for {Adaptive} {Experimental} {Design}},
	url = {https://ieeexplore.ieee.org/document/8957442/},
	doi = {10.1109/ACCESS.2020.2966228},
	abstract = {Bayesian optimisation is a statistical method that efﬁciently models and optimises expensive ‘‘black-box’’ functions. This review considers the application of Bayesian optimisation to experimental design, in comparison to existing Design of Experiments (DOE) methods. Solutions are surveyed for a range of core issues in experimental design including: the incorporation of prior knowledge, high dimensional optimisation, constraints, batch evaluation, multiple objectives, multi-ﬁdelity data, and mixed variable types.},
	language = {en},
	urldate = {2025-02-02},
	journal = {IEEE Access},
	author = {Greenhill, Stewart and Rana, Santu and Gupta, Sunil and Vellanki, Pratibha and Venkatesh, Svetha},
	year = {2020},
	pages = {13937--13948},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\8RKYYFTI\\Greenhill et al. - 2020 - Bayesian Optimization for Adaptive Experimental Design A Review.pdf:application/pdf},
}

@article{ren_survey_2022,
	title = {A {Survey} of {Deep} {Active} {Learning}},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3472291},
	doi = {10.1145/3472291},
	abstract = {Active learning (AL) attempts to maximize a model’s performance gain while annotating the fewest samples possible. Deep learning (DL) is greedy for data and requires a large amount of data supply to optimize a massive number of parameters if the model is to learn how to extract high-quality features. In recent years, due to the rapid development of internet technology, we have entered an era of information abundance characterized by massive amounts of available data. As a result, DL has attracted significant attention from researchers and has been rapidly developed. Compared with DL, however, researchers have a relatively low interest in AL. This is mainly because before the rise of DL, traditional machine learning requires relatively few labeled samples, meaning that early AL is rarely according the value it deserves. Although DL has made breakthroughs in various fields, most of this success is due to a large number of publicly available annotated datasets. However, the acquisition of a large number of high-quality annotated datasets consumes a lot of manpower, making it unfeasible in fields that require high levels of expertise (such as speech recognition, information extraction, medical images, etc.). Therefore, AL is gradually coming to receive the attention it is due.
            It is therefore natural to investigate whether AL can be used to reduce the cost of sample annotation while retaining the powerful learning capabilities of DL. As a result of such investigations, deep active learning (DeepAL) has emerged. Although research on this topic is quite abundant, there has not yet been a comprehensive survey of DeepAL-related works; accordingly, this article aims to fill this gap. We provide a formal classification method for the existing work, along with a comprehensive and systematic overview. In addition, we also analyze and summarize the development of DeepAL from an application perspective. Finally, we discuss the confusion and problems associated with DeepAL and provide some possible development directions.},
	language = {en},
	number = {9},
	urldate = {2025-02-02},
	journal = {ACM Computing Surveys},
	author = {Ren, Pengzhen and Xiao, Yun and Chang, Xiaojun and Huang, Po-Yao and Li, Zhihui and Gupta, Brij B. and Chen, Xiaojiang and Wang, Xin},
	month = dec,
	year = {2022},
	pages = {1--40},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\LS9TG9RS\\Ren et al. - 2022 - A Survey of Deep Active Learning.pdf:application/pdf},
}

@misc{hino_active_2020,
	title = {Active {Learning}: {Problem} {Settings} and {Recent} {Developments}},
	shorttitle = {Active {Learning}},
	url = {http://arxiv.org/abs/2012.04225},
	doi = {10.48550/arXiv.2012.04225},
	abstract = {In supervised learning, acquiring labeled training data for a predictive model can be very costly, but acquiring a large amount of unlabeled data is often quite easy. Active learning is a method of obtaining predictive models with high precision at a limited cost through the adaptive selection of samples for labeling. This paper explains the basic problem settings of active learning and recent research trends. In particular, research on learning acquisition functions to select samples from the data for labeling, theoretical work on active learning algorithms, and stopping criteria for sequential data acquisition are highlighted. Application examples for material development and measurement are introduced.},
	language = {en},
	urldate = {2025-02-02},
	publisher = {arXiv},
	author = {Hino, Hideitsu},
	month = dec,
	year = {2020},
	note = {arXiv:2012.04225 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 31 pages, 2 figures},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\CPGSXHKP\\Hino - 2020 - Active Learning Problem Settings and Recent Developments.pdf:application/pdf},
}

@article{ren_autonomous_2023,
	title = {Autonomous experiments using active learning and {AI}},
	volume = {8},
	issn = {2058-8437},
	url = {https://www.nature.com/articles/s41578-023-00588-4},
	doi = {10.1038/s41578-023-00588-4},
	language = {en},
	number = {9},
	urldate = {2025-02-02},
	journal = {Nature Reviews Materials},
	author = {Ren, Zhichu and Ren, Zekun and Zhang, Zhen and Buonassisi, Tonio and Li, Ju},
	month = aug,
	year = {2023},
	pages = {563--564},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\J9VN3AIM\\Ren et al. - 2023 - Autonomous experiments using active learning and AI.pdf:application/pdf},
}

@article{shahriari_taking_2016,
	title = {Taking the {Human} {Out} of the {Loop}: {A} {Review} of {Bayesian} {Optimization}},
	volume = {104},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/OAPA.html},
	issn = {0018-9219, 1558-2256},
	shorttitle = {Taking the {Human} {Out} of the {Loop}},
	url = {https://ieeexplore.ieee.org/document/7352306/},
	doi = {10.1109/JPROC.2015.2494218},
	abstract = {Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, realtime game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
	language = {en},
	number = {1},
	urldate = {2025-02-02},
	journal = {Proceedings of the IEEE},
	author = {Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P. and De Freitas, Nando},
	month = jan,
	year = {2016},
	pages = {148--175},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\DS8AL8YW\\Shahriari et al. - 2016 - Taking the Human Out of the Loop A Review of Bayesian Optimization.pdf:application/pdf},
}

@misc{frazier_tutorial_2018,
	title = {A {Tutorial} on {Bayesian} {Optimization}},
	url = {http://arxiv.org/abs/1807.02811},
	doi = {10.48550/arXiv.1807.02811},
	abstract = {Bayesian optimization is an approach to optimizing objective functions that take a long time (minutes or hours) to evaluate. It is best-suited for optimization over continuous domains of less than 20 dimensions, and tolerates stochastic noise in function evaluations. It builds a surrogate for the objective and quantiﬁes the uncertainty in that surrogate using a Bayesian machine learning technique, Gaussian process regression, and then uses an acquisition function deﬁned from this surrogate to decide where to sample. In this tutorial, we describe how Bayesian optimization works, including Gaussian process regression and three common acquisition functions: expected improvement, entropy search, and knowledge gradient. We then discuss more advanced techniques, including running multiple function evaluations in parallel, multi-ﬁdelity and multi-information source optimization, expensive-to-evaluate constraints, random environmental conditions, multi-task Bayesian optimization, and the inclusion of derivative information. We conclude with a discussion of Bayesian optimization software and future research directions in the ﬁeld. Within our tutorial material we provide a generalization of expected improvement to noisy evaluations, beyond the noise-free setting where it is more commonly applied. This generalization is justiﬁed by a formal decision-theoretic argument, standing in contrast to previous ad hoc modiﬁcations.},
	language = {en},
	urldate = {2025-02-02},
	publisher = {arXiv},
	author = {Frazier, Peter I.},
	month = jul,
	year = {2018},
	note = {arXiv:1807.02811 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\QR6HILKU\\Frazier - 2018 - A Tutorial on Bayesian Optimization.pdf:application/pdf},
}

@article{lookman_active_2019,
	title = {Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design},
	volume = {5},
	issn = {2057-3960},
	url = {https://www.nature.com/articles/s41524-019-0153-8},
	doi = {10.1038/s41524-019-0153-8},
	abstract = {Abstract
            One of the main challenges in materials discovery is efficiently exploring the vast search space for targeted properties as approaches that rely on trial-and-error are impractical. We review how methods from the information sciences enable us to accelerate the search and discovery of new materials. In particular, active learning allows us to effectively navigate the search space iteratively to identify promising candidates for guiding experiments and computations. The approach relies on the use of uncertainties and making predictions from a surrogate model together with a utility function that prioritizes the decision making process on unexplored data. We discuss several utility functions and demonstrate their use in materials science applications, impacting both experimental and computational research. We summarize by indicating generalizations to multiple properties and multifidelity data, and identify challenges, future directions and opportunities in the emerging field of materials informatics.},
	language = {en},
	number = {1},
	urldate = {2025-02-02},
	journal = {npj Computational Materials},
	author = {Lookman, Turab and Balachandran, Prasanna V. and Xue, Dezhen and Yuan, Ruihao},
	month = feb,
	year = {2019},
	pages = {21},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\ZJDRJ6Y5\\Lookman et al. - 2019 - Active learning in materials science with emphasis on adaptive sampling using uncertainties for targ.pdf:application/pdf},
}

@article{fare_multi-fidelity_2022,
	title = {A multi-fidelity machine learning approach to high throughput materials screening},
	volume = {8},
	issn = {2057-3960},
	url = {https://www.nature.com/articles/s41524-022-00947-9},
	doi = {10.1038/s41524-022-00947-9},
	abstract = {Abstract
            The ever-increasing capability of computational methods has resulted in their general acceptance as a key part of the materials design process. Traditionally this has been achieved using a so-called computational funnel, where increasingly accurate - and expensive – methodologies are used to winnow down a large initial library to a size which can be tackled by experiment. In this paper we present an alternative approach, using a multi-output Gaussian process to fuse the information gained from both experimental and computational methods into a single, dynamically evolving design. Common challenges with computational funnels, such as mis-ordering methods, and the inclusion of non-informative steps are avoided by learning the relationships between methods on the fly. We show this approach reduces overall optimisation cost on average by around a factor of three compared to other commonly used approaches, through evaluation on three challenging materials design problems.},
	language = {en},
	number = {1},
	urldate = {2025-02-02},
	journal = {npj Computational Materials},
	author = {Fare, Clyde and Fenner, Peter and Benatan, Matthew and Varsi, Alessandro and Pyzer-Knapp, Edward O.},
	month = dec,
	year = {2022},
	pages = {257},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\2VLZ5GPC\\Fare et al. - 2022 - A multi-fidelity machine learning approach to high throughput materials screening.pdf:application/pdf},
}

@article{manna_learning_2022,
	title = {Learning in continuous action space for developing high dimensional potential energy models},
	volume = {13},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-27849-6},
	doi = {10.1038/s41467-021-27849-6},
	abstract = {Abstract
            Reinforcement learning (RL) approaches that combine a tree search with deep learning have found remarkable success in searching exorbitantly large, albeit discrete action spaces, as in chess, Shogi and Go. Many real-world materials discovery and design applications, however, involve multi-dimensional search problems and learning domains that have continuous action spaces. Exploring high-dimensional potential energy models of materials is an example. Traditionally, these searches are time consuming (often several years for a single bulk system) and driven by human intuition and/or expertise and more recently by global/local optimization searches that have issues with convergence and/or do not scale well with the search dimensionality. Here, in a departure from discrete action and other gradient-based approaches, we introduce a RL strategy based on decision trees that incorporates modified rewards for improved exploration, efficient sampling during playouts and a “window scaling scheme" for enhanced exploitation, to enable efficient and scalable search for continuous action space problems. Using high-dimensional artificial landscapes and control RL problems, we successfully benchmark our approach against popular global optimization schemes and state of the art policy gradient methods, respectively. We demonstrate its efficacy to parameterize potential models (physics based and high-dimensional neural networks) for 54 different elemental systems across the periodic table as well as alloys. We analyze error trends across different elements in the latent space and trace their origin to elemental structural diversity and the smoothness of the element energy surface. Broadly, our RL strategy will be applicable to many other physical science problems involving search over continuous action spaces.},
	language = {en},
	number = {1},
	urldate = {2025-02-02},
	journal = {Nature Communications},
	author = {Manna, Sukriti and Loeffler, Troy D. and Batra, Rohit and Banik, Suvo and Chan, Henry and Varughese, Bilvin and Sasikumar, Kiran and Sternberg, Michael and Peterka, Tom and Cherukara, Mathew J. and Gray, Stephen K. and Sumpter, Bobby G. and Sankaranarayanan, Subramanian K. R. S.},
	month = jan,
	year = {2022},
	pages = {368},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\GX9K4YGC\\Manna et al. - 2022 - Learning in continuous action space for developing high dimensional potential energy models.pdf:application/pdf},
}

@article{banik_continuous_2023,
	title = {A {Continuous} {Action} {Space} {Tree} search for {INverse} {desiGn} ({CASTING}) framework for materials discovery},
	volume = {9},
	issn = {2057-3960},
	url = {https://www.nature.com/articles/s41524-023-01128-y},
	doi = {10.1038/s41524-023-01128-y},
	abstract = {Abstract
            Material properties share an intrinsic relationship with their structural attributes, making inverse design approaches crucial for discovering new materials with desired functionalities. Reinforcement Learning (RL) approaches are emerging as powerful inverse design tools, often functioning in discrete action spaces. This constrains their application in materials design problems, which involve continuous search spaces. Here, we introduce an RL-based framework CASTING (Continuous Action Space Tree Search for inverse design), that employs a decision tree-based Monte Carlo Tree Search (MCTS) algorithm with continuous space adaptation through modified policies and sampling. Using representative examples like Silver (Ag) for metals, Carbon (C) for covalent systems, and multicomponent systems such as graphane, boron nitride, and complex correlated oxides, we showcase its accuracy, convergence speed, and scalability in materials discovery and design. Furthermore, with the inverse design of super-hard Carbon phases, we demonstrate CASTING’s utility in discovering metastable phases tailored to user-defined target properties and preferences.},
	language = {en},
	number = {1},
	urldate = {2025-02-02},
	journal = {npj Computational Materials},
	author = {Banik, Suvo and Loefller, Troy and Manna, Sukriti and Chan, Henry and Srinivasan, Srilok and Darancet, Pierre and Hexemer, Alexander and Sankaranarayanan, Subramanian K. R. S.},
	month = sep,
	year = {2023},
	pages = {177},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\7Q7W8PDU\\Banik et al. - 2023 - A Continuous Action Space Tree search for INverse desiGn (CASTING) framework for materials discovery.pdf:application/pdf},
}

@article{jablonka_bias_2021,
	title = {Bias free multiobjective active learning for materials design and discovery},
	volume = {12},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-22437-0},
	doi = {10.1038/s41467-021-22437-0},
	abstract = {Abstract
            The design rules for materials are clear for applications with a single objective. For most applications, however, there are often multiple, sometimes competing objectives where there is no single best material and the design rules change to finding the set of Pareto optimal materials. In this work, we leverage an active learning algorithm that directly uses the Pareto dominance relation to compute the set of Pareto optimal materials with desirable accuracy. We apply our algorithm to de novo polymer design with a prohibitively large search space. Using molecular simulations, we compute key descriptors for dispersant applications and drastically reduce the number of materials that need to be evaluated to reconstruct the Pareto front with a desired confidence. This work showcases how simulation and machine learning techniques can be coupled to discover materials within a design space that would be intractable using conventional screening approaches.},
	language = {en},
	number = {1},
	urldate = {2025-02-02},
	journal = {Nature Communications},
	author = {Jablonka, Kevin Maik and Jothiappan, Giriprasad Melpatti and Wang, Shefang and Smit, Berend and Yoo, Brian},
	month = apr,
	year = {2021},
	pages = {2312},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\KGQTPL3L\\Jablonka et al. - 2021 - Bias free multiobjective active learning for materials design and discovery.pdf:application/pdf},
}

@article{noack_autonomous_2020,
	title = {Autonomous materials discovery driven by {Gaussian} process regression with inhomogeneous measurement noise and anisotropic kernels},
	volume = {10},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-74394-1},
	doi = {10.1038/s41598-020-74394-1},
	abstract = {Abstract
            A majority of experimental disciplines face the challenge of exploring large and high-dimensional parameter spaces in search of new scientific discoveries. Materials science is no exception; the wide variety of synthesis, processing, and environmental conditions that influence material properties gives rise to particularly vast parameter spaces. Recent advances have led to an increase in the efficiency of materials discovery by increasingly automating the exploration processes. Methods for autonomous experimentation have become more sophisticated recently, allowing for multi-dimensional parameter spaces to be explored efficiently and with minimal human intervention, thereby liberating the scientists to focus on interpretations and big-picture decisions. Gaussian process regression (GPR) techniques have emerged as the method of choice for steering many classes of experiments. We have recently demonstrated the positive impact of GPR-driven decision-making algorithms on autonomously-steered experiments at a synchrotron beamline. However, due to the complexity of the experiments, GPR often cannot be used in its most basic form, but rather has to be tuned to account for the special requirements of the experiments. Two requirements seem to be of particular importance, namely inhomogeneous measurement noise (input-dependent or non-i.i.d.) and anisotropic kernel functions, which are the two concepts that we tackle in this paper. Our synthetic and experimental tests demonstrate the importance of both concepts for experiments in materials science and the benefits that result from including them in the autonomous decision-making process.},
	language = {en},
	number = {1},
	urldate = {2025-02-02},
	journal = {Scientific Reports},
	author = {Noack, Marcus M. and Doerk, Gregory S. and Li, Ruipeng and Streit, Jason K. and Vaia, Richard A. and Yager, Kevin G. and Fukuto, Masafumi},
	month = oct,
	year = {2020},
	pages = {17663},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\8P965VCB\\Noack et al. - 2020 - Autonomous materials discovery driven by Gaussian process regression with inhomogeneous measurement.pdf:application/pdf},
}

@article{biswas_dynamic_2024,
	title = {A dynamic {Bayesian} optimized active recommender system for curiosity-driven partially {Human}-in-the-loop automated experiments},
	volume = {10},
	issn = {2057-3960},
	url = {https://www.nature.com/articles/s41524-023-01191-5},
	doi = {10.1038/s41524-023-01191-5},
	abstract = {Abstract
            Optimization of experimental materials synthesis and characterization through active learning methods has been growing over the last decade, with examples ranging from measurements of diffraction on combinatorial alloys at synchrotrons, to searches through chemical space with automated synthesis robots for perovskites. In virtually all cases, the target property of interest for optimization is defined a priori with the ability to shift the trajectory of the optimization based on human-identified findings during the experiment is lacking. Thus, to highlight the best of both human operators and AI-driven experiments, here we present the development of a human–AI collaborated experimental workflow, via a Bayesian optimized active recommender system (BOARS), to shape targets on the fly with human real-time feedback. Here, the human guidance overpowers AI at early iteration when prior knowledge (uncertainty) is minimal (higher), while the AI overpowers the human during later iterations to accelerate the process with the human-assessed goal. We showcase examples of this framework applied to pre-acquired piezoresponse force spectroscopy of a ferroelectric thin film, and in real-time on an atomic force microscope, with human assessment to find symmetric hysteresis loops. It is found that such features appear more affected by subsurface defects than the local domain structure. This work shows the utility of human–AI approaches for curiosity driven exploration of systems across experimental domains.},
	language = {en},
	number = {1},
	urldate = {2025-02-02},
	journal = {npj Computational Materials},
	author = {Biswas, Arpan and Liu, Yongtao and Creange, Nicole and Liu, Yu-Chen and Jesse, Stephen and Yang, Jan-Chi and Kalinin, Sergei V. and Ziatdinov, Maxim A. and Vasudevan, Rama K.},
	month = feb,
	year = {2024},
	pages = {29},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\YZ33D4LC\\Biswas et al. - 2024 - A dynamic Bayesian optimized active recommender system for curiosity-driven partially Human-in-the-l.pdf:application/pdf},
}

@article{kusne_--fly_2020,
	title = {On-the-fly closed-loop materials discovery via {Bayesian} active learning},
	volume = {11},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-19597-w},
	doi = {10.1038/s41467-020-19597-w},
	abstract = {Abstract
            Active learning—the field of machine learning (ML) dedicated to optimal experiment design—has played a part in science as far back as the 18th century when Laplace used it to guide his discovery of celestial mechanics. In this work, we focus a closed-loop, active learning-driven autonomous system on another major challenge, the discovery of advanced materials against the exceedingly complex synthesis-processes-structure-property landscape. We demonstrate an autonomous materials discovery methodology for functional inorganic compounds which allow scientists to fail smarter, learn faster, and spend less resources in their studies, while simultaneously improving trust in scientific results and machine learning tools. This robot science enables science-over-the-network, reducing the economic impact of scientists being physically separated from their labs. The real-time closed-loop, autonomous system for materials exploration and optimization (CAMEO) is implemented at the synchrotron beamline to accelerate the interconnected tasks of phase mapping and property optimization, with each cycle taking seconds to minutes. We also demonstrate an embodiment of human-machine interaction, where human-in-the-loop is called to play a contributing role within each cycle. This work has resulted in the discovery of a novel epitaxial nanocomposite phase-change memory material.},
	language = {en},
	number = {1},
	urldate = {2025-02-02},
	journal = {Nature Communications},
	author = {Kusne, A. Gilad and Yu, Heshan and Wu, Changming and Zhang, Huairuo and Hattrick-Simpers, Jason and DeCost, Brian and Sarker, Suchismita and Oses, Corey and Toher, Cormac and Curtarolo, Stefano and Davydov, Albert V. and Agarwal, Ritesh and Bendersky, Leonid A. and Li, Mo and Mehta, Apurva and Takeuchi, Ichiro},
	month = nov,
	year = {2020},
	pages = {5966},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\NGHRWV9U\\Kusne et al. - 2020 - On-the-fly closed-loop materials discovery via Bayesian active learning.pdf:application/pdf},
}

@article{chitturi_targeted_2024,
	title = {Targeted materials discovery using {Bayesian} algorithm execution},
	volume = {10},
	issn = {2057-3960},
	url = {https://www.nature.com/articles/s41524-024-01326-2},
	doi = {10.1038/s41524-024-01326-2},
	abstract = {Abstract
            
              Rapid discovery and synthesis of future materials requires intelligent data acquisition strategies to navigate large design spaces. A popular strategy is Bayesian optimization, which aims to find candidates that maximize material properties; however, materials design often requires finding specific subsets of the design space which meet more complex or specialized goals. We present a framework that captures experimental goals through straightforward user-defined filtering algorithms. These algorithms are automatically translated into one of three intelligent, parameter-free, sequential data collection strategies (SwitchBAX, InfoBAX, and MeanBAX), bypassing the time-consuming and difficult process of task-specific acquisition function design. Our framework is tailored for typical discrete search spaces involving multiple measured physical properties and short time-horizon decision making. We demonstrate this approach on datasets for TiO
              2
              nanoparticle synthesis and magnetic materials characterization, and show that our methods are significantly more efficient than state-of-the-art approaches. Overall, our framework provides a practical solution for navigating the complexities of materials design, and helps lay groundwork for the accelerated development of advanced materials.},
	language = {en},
	number = {1},
	urldate = {2025-02-02},
	journal = {npj Computational Materials},
	author = {Chitturi, Sathya R. and Ramdas, Akash and Wu, Yue and Rohr, Brian and Ermon, Stefano and Dionne, Jennifer and Jornada, Felipe H. Da and Dunne, Mike and Tassone, Christopher and Neiswanger, Willie and Ratner, Daniel},
	month = jul,
	year = {2024},
	pages = {156},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\YNZ8WUJ3\\Chitturi et al. - 2024 - Targeted materials discovery using Bayesian algorithm execution.pdf:application/pdf},
}

@article{ma_mlmd_2024,
	title = {{MLMD}: a programming-free {AI} platform to predict and design materials},
	volume = {10},
	issn = {2057-3960},
	shorttitle = {{MLMD}},
	url = {https://www.nature.com/articles/s41524-024-01243-4},
	doi = {10.1038/s41524-024-01243-4},
	abstract = {Abstract
            Accelerating the discovery of advanced materials is crucial for modern industries, aerospace, biomedicine, and energy. Nevertheless, only a small fraction of materials are currently under experimental investigation within the vast chemical space. Materials scientists are plagued by time-consuming and labor-intensive experiments due to lacking efficient material discovery strategies. Artificial intelligence (AI) has emerged as a promising instrument to bridge this gap. Although numerous AI toolkits or platforms for material science have been developed, they suffer from many shortcomings. These include primarily focusing on material property prediction and being unfriendly to material scientists lacking programming experience, especially performing poorly with limited data. Here, we developed MLMD, an AI platform for materials design. It is capable of effectively discovering novel materials with high-potential advanced properties end-to-end, utilizing model inference, surrogate optimization, and even working in situations of data scarcity based on active learning. Additionally, it integrates data analysis, descriptor refactoring, hyper-parameters auto-optimizing, and properties prediction. It also provides a web-based friendly interface without need programming and can be used anywhere, anytime. MLMD is dedicated to the integration of material experiment/computation and design, and accelerate the new material discovery with desired one or multiple properties. It demonstrates the strong power to direct experiments on various materials (perovskites, steel, high-entropy alloy, etc). MLMD will be an essential tool for materials scientists and facilitate the advancement of materials informatics.},
	language = {en},
	number = {1},
	urldate = {2025-02-02},
	journal = {npj Computational Materials},
	author = {Ma, Jiaxuan and Cao, Bin and Dong, Shuya and Tian, Yuan and Wang, Menghuan and Xiong, Jie and Sun, Sheng},
	month = mar,
	year = {2024},
	pages = {59},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\PSN5YM22\\Ma et al. - 2024 - MLMD a programming-free AI platform to predict and design materials.pdf:application/pdf},
}

@article{wang_recent_2023,
	title = {Recent {Advances} in {Bayesian} {Optimization}},
	volume = {55},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3582078},
	doi = {10.1145/3582078},
	abstract = {Bayesian optimization has emerged at the forefront of expensive black-box optimization due to its data efficiency. Recent years have witnessed a proliferation of studies on the development of new Bayesian optimization algorithms and their applications. Hence, this article attempts to provide a comprehensive and updated survey of recent advances in Bayesian optimization that are mainly based on Gaussian processes and identify challenging open problems. We categorize the existing work on Bayesian optimization into nine main groups according to the motivations and focus of the proposed algorithms. For each category, we present the main advances with respect to the construction of surrogate models and adaptation of the acquisition functions. Finally, we discuss the open questions and suggest promising future research directions, in particular with regard to heterogeneity, privacy preservation, and fairness in distributed and federated optimization systems.},
	language = {en},
	number = {13s},
	urldate = {2025-02-02},
	journal = {ACM Computing Surveys},
	author = {Wang, Xilu and Jin, Yaochu and Schmitt, Sebastian and Olhofer, Markus},
	month = dec,
	year = {2023},
	pages = {1--36},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\T9QY5GJL\\Wang et al. - 2023 - Recent Advances in Bayesian Optimization.pdf:application/pdf},
}

@article{settles_theories_nodate,
	title = {From {Theories} to {Queries}: {Active} {Learning} in {Practice}},
	abstract = {This article surveys recent work in active learning aimed at making it more practical for real-world use. In general, active learning systems aim to make machine learning more economical, since they can participate in the acquisition of their own training data. An active learner might iteratively select informative query instances to be labeled by an oracle, for example. Work over the last two decades has shown that such approaches are eﬀective at maintaining accuracy while reducing training set size in many machine learning applications. However, as we begin to deploy active learning in real ongoing learning systems and data annotation projects, we are encountering unexpected problems—due in part to practical realities that violate the basic assumptions of earlier foundational work. I review some of these issues, and discuss recent work being done to address the challenges.},
	language = {en},
	author = {Settles, Burr},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\GGDCGLN6\\Settles - From Theories to Queries Active Learning in Practice.pdf:application/pdf},
}

@article{wu_deep_2022,
	title = {Deep {Active} {Learning} for {Computer} {Vision} {Tasks}: {Methodologies}, {Applications}, and {Challenges}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2076-3417},
	shorttitle = {Deep {Active} {Learning} for {Computer} {Vision} {Tasks}},
	url = {https://www.mdpi.com/2076-3417/12/16/8103},
	doi = {10.3390/app12168103},
	abstract = {Active learning is a label-efﬁcient machine learning method that actively selects the most valuable unlabeled samples to annotate. Active learning focuses on achieving the best possible performance while using as few, high-quality sample annotations as possible. Recently, active learning achieved promotion combined with deep learning-based methods, which are named deep active learning methods in this paper. Deep active learning plays a crucial role in computer vision tasks, especially in label-insensitive scenarios, such as hard-to-label tasks (medical images analysis) and time-consuming tasks (autonomous driving). However, deep active learning still has some challenges, such as unstable performance and dirty data, which are future research trends. Compared with other reviews on deep active learning, our work introduced the deep active learning from computer vision-related methodologies and corresponding applications. The expected audience of this vision-friendly survey are researchers who are working in computer vision but willing to utilize deep active learning methods to solve vision problems. Speciﬁcally, this review systematically focuses on the details of methods, applications, and challenges in vision tasks, and we also introduce the classic theories, strategies, and scenarios of active learning in brief.},
	language = {en},
	number = {16},
	urldate = {2025-02-02},
	journal = {Applied Sciences},
	author = {Wu, Mingfei and Li, Chen and Yao, Zehuan},
	month = aug,
	year = {2022},
	pages = {8103},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\35J8G3M6\\Wu et al. - 2022 - Deep Active Learning for Computer Vision Tasks Methodologies, Applications, and Challenges.pdf:application/pdf},
}

@article{wan_survey_2023,
	title = {A {Survey} of {Deep} {Active} {Learning} for {Foundation} {Models}},
	volume = {2},
	issn = {2771-5892},
	url = {https://spj.science.org/doi/10.34133/icomputing.0058},
	doi = {10.34133/icomputing.0058},
	abstract = {Active learning (AL) is an effective sample selection approach that annotates only a subset of the training data to address the challenge of data annotation, and deep learning (DL) is data-intensive and reliant on abundant training data. Deep active learning (DeepAL) benefits from the integration of AL and DL, offering an efficient solution that balances model performance and annotation costs. The importance of DeepAL has been increasingly recognized with the emergence of large foundation models that depend heavily on substantial computational resources and extensive training data. This survey endeavors to provide a comprehensive overview of DeepAL. Specifically, we first analyze and summarize various sample query strategies, data querying considerations, model training paradigms, and real-world applications of DeepAL. In addition, we discuss the challenges that arise in the era of foundation models and propose potential directions for future AL research. The survey aims to bridge a gap in the existing literature by organizing and summarizing current approaches, offering insights into DeepAL and highlighting the necessity of developing specialized DeepAL techniques tailored to foundation models. By critically examining the current state of DeepAL, this survey contributes to a more profound understanding of the field and serves as a guide for researchers and practitioners interested in DeepAL techniques.},
	language = {en},
	urldate = {2025-02-02},
	journal = {Intelligent Computing},
	author = {Wan, Tianjiao and Xu, Kele and Yu, Ting and Wang, Xu and Feng, Dawei and Ding, Bo and Wang, Huaimin},
	month = jan,
	year = {2023},
	pages = {0058},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\NXRX4DWY\\Wan et al. - 2023 - A Survey of Deep Active Learning for Foundation Models.pdf:application/pdf},
}

@misc{mohamadi_deep_2022,
	title = {Deep {Bayesian} {Active} {Learning}, {A} {Brief} {Survey} on {Recent} {Advances}},
	url = {http://arxiv.org/abs/2012.08044},
	doi = {10.48550/arXiv.2012.08044},
	abstract = {Active learning frameworks offer efﬁcient data annotation without remarkable accuracy degradation. In other words, active learning starts training the model with a small size of labeled data while exploring the space of unlabeled data in order to select most informative samples to be labeled. Generally speaking, representing the uncertainty is crucial in any active learning framework, however, deep learning methods are not capable of either representing or manipulating model uncertainty. On the other hand, from the real world application perspective, uncertainty representation is getting more and more attention in the machine learning community. Deep Bayesian active learning frameworks and generally any Bayesian active learning settings, provide practical consideration in the model which allows training with small data while representing the model uncertainty for further efﬁcient training. In this paper, we brieﬂy survey recent advances in Bayesian active learning and in particular deep Bayesian active learning frameworks.},
	language = {en},
	urldate = {2025-02-02},
	publisher = {arXiv},
	author = {Mohamadi, Salman and Amindavar, Hamidreza},
	month = apr,
	year = {2022},
	note = {arXiv:2012.08044 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\QI8ZU2E3\\Mohamadi and Amindavar - 2022 - Deep Bayesian Active Learning, A Brief Survey on Recent Advances.pdf:application/pdf},
}

@misc{motsoehli_deep_2023,
	title = {Deep {Active} {Learning} in the {Presence} of {Label} {Noise}: {A} {Survey}},
	shorttitle = {Deep {Active} {Learning} in the {Presence} of {Label} {Noise}},
	url = {http://arxiv.org/abs/2302.11075},
	doi = {10.48550/arXiv.2302.11075},
	abstract = {Deep active learning has emerged as a powerful tool for training deep learning models within a predefined labeling budget. These models have achieved performances comparable to those trained in an offline setting. However, deep active learning faces substantial issues when dealing with classification datasets containing noisy labels. In this literature review, we discuss the current state of deep active learning in the presence of label noise, highlighting unique approaches, their strengths, and weaknesses. With the recent success of vision transformers in image classification tasks, we provide a brief overview and consider how the transformer layers and attention mechanisms can be used to enhance diversity, importance, and uncertainty-based selection in queries sent to an oracle for labeling. We further propose exploring contrastive learning methods to derive good image representations that can aid in selecting high-value samples for labeling in an active learning setting. We also highlight the need for creating unified benchmarks and standardized datasets for deep active learning in the presence of label noise for image classification to promote the reproducibility of research. The review concludes by suggesting avenues for future research in this area.},
	language = {en},
	urldate = {2025-02-02},
	publisher = {arXiv},
	author = {Mots'oehli, Moseli and Baek, Kyungim},
	month = sep,
	year = {2023},
	note = {arXiv:2302.11075 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: 20 pages, PhD literature review},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\WPQFU7QS\\Mots'oehli and Baek - 2023 - Deep Active Learning in the Presence of Label Noise A Survey.pdf:application/pdf},
}

@article{ghozatlou_review_2024,
	title = {A {Review} and a {Perspective} of {Deep} {Active} {Learning} for {Remote} {Sensing} {Image} {Analysis}: {Enhanced} adaptation to user conjecture},
	volume = {12},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2168-6831, 2473-2397, 2373-7468},
	shorttitle = {A {Review} and a {Perspective} of {Deep} {Active} {Learning} for {Remote} {Sensing} {Image} {Analysis}},
	url = {https://ieeexplore.ieee.org/document/10549792/},
	doi = {10.1109/MGRS.2024.3403423},
	language = {en},
	number = {3},
	urldate = {2025-02-02},
	journal = {IEEE Geoscience and Remote Sensing Magazine},
	author = {Ghozatlou, Omid and Datcu, Mihai and Focsa, Adrian and Heredia Conde, Miguel and Ullo, Silvia Liberata},
	month = sep,
	year = {2024},
	pages = {125--148},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\J47THG7C\\Ghozatlou et al. - 2024 - A Review and a Perspective of Deep Active Learning for Remote Sensing Image Analysis Enhanced adapt.pdf:application/pdf},
}

@article{rainforth_modern_2024,
	title = {Modern {Bayesian} {Experimental} {Design}},
	volume = {39},
	issn = {0883-4237},
	url = {https://projecteuclid.org/journals/statistical-science/volume-39/issue-1/Modern-Bayesian-Experimental-Design/10.1214/23-STS915.full},
	doi = {10.1214/23-STS915},
	abstract = {Bayesian experimental design (BED) provides a powerful and general framework for optimizing the design of experiments. However, its deployment often poses substantial computational challenges that can undermine its practical use. In this review, we outline how recent advances have transformed our ability to overcome these challenges and thus utilize BED effectively, before discussing some areas for future development in the ﬁeld. Key words and phrases: Bayesian optimal design, Bayesian adaptive design, active learning, information maximization.},
	language = {en},
	number = {1},
	urldate = {2025-02-02},
	journal = {Statistical Science},
	author = {Rainforth, Tom and Foster, Adam and Ivanova, Desi R. and Bickford Smith, Freddie},
	month = feb,
	year = {2024},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\F2ALEBBW\\Rainforth et al. - 2024 - Modern Bayesian Experimental Design.pdf:application/pdf},
}

@article{li_survey_2024,
	title = {A {Survey} on {Deep} {Active} {Learning}: {Recent} {Advances} and {New} {Frontiers}},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2162-237X, 2162-2388},
	shorttitle = {A {Survey} on {Deep} {Active} {Learning}},
	url = {https://ieeexplore.ieee.org/document/10537213/},
	doi = {10.1109/TNNLS.2024.3396463},
	abstract = {Active learning seeks to achieve strong performance with fewer training samples. It does this by iteratively asking an oracle to label newly selected samples in a human-in-the-loop manner. This technique has gained increasing popularity due to its broad applicability, yet its survey papers, especially for deep active learning (DAL), remain scarce. Therefore, we conduct an advanced and comprehensive survey on DAL. We first introduce reviewed paper collection and filtering. Second, we formally define the DAL task and summarize the most influential baselines and widely used datasets. Third, we systematically provide a taxonomy of DAL methods from five perspectives, including annotation types, query strategies, deep model architectures, learning paradigms, and training processes, and objectively analyze their strengths and weaknesses. Then, we comprehensively summarize the main applications of DAL in natural language processing (NLP), computer vision (CV), data mining (DM), and so on. Finally, we discuss challenges and perspectives after a detailed analysis of current studies. This work aims to serve as a useful and quick guide for researchers in overcoming difficulties in DAL. We hope that this survey will spur further progress in this burgeoning field.},
	language = {en},
	urldate = {2025-02-02},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Li, Dongyuan and Wang, Zhen and Chen, Yankai and Jiang, Renhe and Ding, Weiping and Okumura, Manabu},
	year = {2024},
	pages = {1--21},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\VZUSXCXY\\Li et al. - 2024 - A Survey on Deep Active Learning Recent Advances and New Frontiers.pdf:application/pdf},
}

@article{navon_learning_2021,
	title = {{LEARNING} {THE} {PARETO} {FRONT} {WITH} {HYPERNETWORKS}},
	abstract = {Multi-objective optimization (MOO) problems are prevalent in machine learning. These problems have a set of optimal solutions, called the Pareto front, where each point on the front represents a different trade-off between possibly conﬂicting objectives. Recent MOO methods can target a speciﬁc desired ray in loss space however, most approaches still face two grave limitations: (i) A separate model has to be trained for each point on the front; and (ii) The exact trade-off must be known before the optimization process. Here, we tackle the problem of learning the entire Pareto front, with the capability of selecting a desired operating point on the front after training. We call this new setup Pareto-Front Learning (PFL).},
	language = {en},
	author = {Navon, Aviv and Shamsian, Aviv and Fetaya, Ethan and Chechik, Gal},
	year = {2021},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\MWXJRCVU\\Navon et al. - 2021 - LEARNING THE PARETO FRONT WITH HYPERNETWORKS.pdf:application/pdf},
}

@article{karl_multi-objective_2023,
	title = {Multi-{Objective} {Hyperparameter} {Optimization} in {Machine} {Learning}—{An} {Overview}},
	volume = {3},
	issn = {2688-299X, 2688-3007},
	url = {https://dl.acm.org/doi/10.1145/3610536},
	doi = {10.1145/3610536},
	abstract = {Hyperparameter optimization constitutes a large part of typical modern machine learning (ML) workflows. This arises from the fact that ML methods and corresponding preprocessing steps often only yield optimal performance when hyperparameters are properly tuned. But in many applications, we are not only interested in optimizing ML pipelines solely for predictive accuracy; additional metrics or constraints must be considered when determining an optimal configuration, resulting in a multi-objective optimization problem. This is often neglected in practice, due to a lack of knowledge and readily available software implementations for multi-objective hyperparameter optimization. In this work, we introduce the reader to the basics of multi-objective hyperparameter optimization and motivate its usefulness in applied ML. Furthermore, we provide an extensive survey of existing optimization strategies from the domains of evolutionary algorithms and Bayesian optimization. We illustrate the utility of multi-objective optimization in several specific ML applications, considering objectives such as operating conditions, prediction time, sparseness, fairness, interpretability, and robustness.},
	language = {en},
	number = {4},
	urldate = {2025-02-08},
	journal = {ACM Transactions on Evolutionary Learning and Optimization},
	author = {Karl, Florian and Pielok, Tobias and Moosbauer, Julia and Pfisterer, Florian and Coors, Stefan and Binder, Martin and Schneider, Lennart and Thomas, Janek and Richter, Jakob and Lang, Michel and Garrido-Merchán, Eduardo C. and Branke, Juergen and Bischl, Bernd},
	month = dec,
	year = {2023},
	pages = {1--50},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\A7UXT7ZK\\Karl et al. - 2023 - Multi-Objective Hyperparameter Optimization in Machine Learning—An Overview.pdf:application/pdf},
}

@article{bischl_hyperparameter_2023,
	title = {Hyperparameter optimization: {Foundations}, algorithms, best practices, and open challenges},
	volume = {13},
	issn = {1942-4787, 1942-4795},
	shorttitle = {Hyperparameter optimization},
	url = {https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1484},
	doi = {10.1002/widm.1484},
	abstract = {Most machine learning algorithms are configured by a set of hyperparameters whose values must be carefully chosen and which often considerably impact performance. To avoid a time-consuming and irreproducible manual process of trial-anderror to find well-performing hyperparameter configurations, various automatic hyperparameter optimization (HPO) methods—for example, based on resampling error estimation for supervised machine learning—can be employed. After introducing HPO from a general perspective, this paper reviews important HPO methods, from simple techniques such as grid or random search to more advanced methods like evolution strategies, Bayesian optimization, Hyperband, and racing. This work gives practical recommendations regarding important choices to be made when conducting HPO, including the HPO algorithms themselves, performance evaluation, how to combine HPO with machine learning pipelines, runtime improvements, and parallelization.},
	language = {en},
	number = {2},
	urldate = {2025-02-08},
	journal = {WIREs Data Mining and Knowledge Discovery},
	author = {Bischl, Bernd and Binder, Martin and Lang, Michel and Pielok, Tobias and Richter, Jakob and Coors, Stefan and Thomas, Janek and Ullmann, Theresa and Becker, Marc and Boulesteix, Anne‐Laure and Deng, Difan and Lindauer, Marius},
	month = mar,
	year = {2023},
	pages = {e1484},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\TAGLX9E5\\Bischl et al. - 2023 - Hyperparameter optimization Foundations, algorithms, best practices, and open challenges.pdf:application/pdf},
}

@misc{balandat_botorch_2020,
	title = {{BoTorch}: {A} {Framework} for {Efficient} {Monte}-{Carlo} {Bayesian} {Optimization}},
	shorttitle = {{BoTorch}},
	url = {http://arxiv.org/abs/1910.06403},
	doi = {10.48550/arXiv.1910.06403},
	abstract = {Bayesian optimization provides sample-efﬁcient global optimization for a broad range of applications, including automatic machine learning, engineering, physics, and experimental design. We introduce BOTORCH, a modern programming framework for Bayesian optimization that combines Monte-Carlo (MC) acquisition functions, a novel sample average approximation optimization approach, autodifferentiation, and variance reduction techniques. BOTORCH’s modular design facilitates ﬂexible speciﬁcation and optimization of probabilistic models written in PyTorch, simplifying implementation of new acquisition functions. Our approach is backed by novel theoretical convergence results and made practical by a distinctive algorithmic foundation that leverages fast predictive distributions, hardware acceleration, and deterministic optimization. We also propose a novel “one-shot” formulation of the Knowledge Gradient, enabled by a combination of our theoretical and software contributions. In experiments, we demonstrate the improved sample efﬁciency of BOTORCH relative to other popular libraries.},
	language = {en},
	urldate = {2025-02-08},
	publisher = {arXiv},
	author = {Balandat, Maximilian and Karrer, Brian and Jiang, Daniel R. and Daulton, Samuel and Letham, Benjamin and Wilson, Andrew Gordon and Bakshy, Eytan},
	month = dec,
	year = {2020},
	note = {arXiv:1910.06403 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control, Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\I69NFH7F\\Balandat et al. - 2020 - BoTorch A Framework for Efficient Monte-Carlo Bayesian Optimization.pdf:application/pdf},
}

@article{blank_pymoo_2020,
	title = {Pymoo: {Multi}-{Objective} {Optimization} in {Python}},
	volume = {8},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	shorttitle = {Pymoo},
	url = {https://ieeexplore.ieee.org/document/9078759/},
	doi = {10.1109/ACCESS.2020.2990567},
	abstract = {Python has become the programming language of choice for research and industry projects related to data science, machine learning, and deep learning. Since optimization is an inherent part of these research ﬁelds, more optimization related frameworks have arisen in the past few years. Only a few of them support optimization of multiple conﬂicting objectives at a time, but do not provide comprehensive tools for a complete multi-objective optimization task. To address this issue, we have developed pymoo, a multiobjective optimization framework in Python. We provide a guide to getting started with our framework by demonstrating the implementation of an exemplary constrained multi-objective optimization scenario. Moreover, we give a high-level overview of the architecture of pymoo to show its capabilities followed by an explanation of each module and its corresponding sub-modules. The implementations in our framework are customizable and algorithms can be modiﬁed/extended by supplying custom operators. Moreover, a variety of single, multi- and many-objective test problems are provided and gradients can be retrieved by automatic differentiation out of the box. Also, pymoo addresses practical needs, such as the parallelization of function evaluations, methods to visualize low and high-dimensional spaces, and tools for multi-criteria decision making. For more information about pymoo, readers are encouraged to visit: https://pymoo.org.},
	language = {en},
	urldate = {2025-02-08},
	journal = {IEEE Access},
	author = {Blank, Julian and Deb, Kalyanmoy},
	year = {2020},
	pages = {89497--89509},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\LE3B9J2F\\Blank and Deb - 2020 - Pymoo Multi-Objective Optimization in Python.pdf:application/pdf},
}

@misc{li_hyperband_2018,
	title = {Hyperband: {A} {Novel} {Bandit}-{Based} {Approach} to {Hyperparameter} {Optimization}},
	shorttitle = {Hyperband},
	url = {http://arxiv.org/abs/1603.06560},
	doi = {10.48550/arXiv.1603.06560},
	abstract = {Performance of machine learning algorithms depends critically on identifying a good set of hyperparameters. While recent approaches use Bayesian optimization to adaptively select conﬁgurations, we focus on speeding up random search through adaptive resource allocation and early-stopping. We formulate hyperparameter optimization as a pure-exploration nonstochastic inﬁnite-armed bandit problem where a predeﬁned resource like iterations, data samples, or features is allocated to randomly sampled conﬁgurations. We introduce a novel algorithm, Hyperband, for this framework and analyze its theoretical properties, providing several desirable guarantees. Furthermore, we compare Hyperband with popular Bayesian optimization methods on a suite of hyperparameter optimization problems. We observe that Hyperband can provide over an order-of-magnitude speedup over our competitor set on a variety of deep-learning and kernel-based learning problems.},
	language = {en},
	urldate = {2025-02-08},
	publisher = {arXiv},
	author = {Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
	month = jun,
	year = {2018},
	note = {arXiv:1603.06560 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Changes: - Updated to JMLR version},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\89DCKKS6\\Li et al. - 2018 - Hyperband A Novel Bandit-Based Approach to Hyperparameter Optimization.pdf:application/pdf},
}

@misc{falkner_bohb_2018,
	title = {{BOHB}: {Robust} and {Efficient} {Hyperparameter} {Optimization} at {Scale}},
	shorttitle = {{BOHB}},
	url = {http://arxiv.org/abs/1807.01774},
	doi = {10.48550/arXiv.1807.01774},
	abstract = {Modern deep learning methods are very sensitive to many hyperparameters, and, due to the long training times of state-of-the-art models, vanilla Bayesian hyperparameter optimization is typically computationally infeasible. On the other hand, bandit-based conﬁguration evaluation approaches based on random search lack guidance and do not converge to the best conﬁgurations as quickly. Here, we propose to combine the beneﬁts of both Bayesian optimization and banditbased methods, in order to achieve the best of both worlds: strong anytime performance and fast convergence to optimal conﬁgurations. We propose a new practical state-of-the-art hyperparameter optimization method, which consistently outperforms both Bayesian optimization and Hyperband on a wide range of problem types, including high-dimensional toy functions, support vector machines, feed-forward neural networks, Bayesian neural networks, deep reinforcement learning, and convolutional neural networks. Our method is robust and versatile, while at the same time being conceptually simple and easy to implement.},
	language = {en},
	urldate = {2025-02-08},
	publisher = {arXiv},
	author = {Falkner, Stefan and Klein, Aaron and Hutter, Frank},
	month = jul,
	year = {2018},
	note = {arXiv:1807.01774 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: published at ICML2018},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\B5T62GAZ\\Falkner et al. - 2018 - BOHB Robust and Efficient Hyperparameter Optimization at Scale.pdf:application/pdf},
}

@book{rudolph_parallel_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Parallel {Problem} {Solving} from {Nature} – {PPSN} {XVII}: 17th {International} {Conference}, {PPSN} 2022, {Dortmund}, {Germany}, {September} 10–14, 2022, {Proceedings}, {Part} {I}},
	volume = {13398},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-031-14713-5 978-3-031-14714-2},
	shorttitle = {Parallel {Problem} {Solving} from {Nature} – {PPSN} {XVII}},
	url = {https://link.springer.com/10.1007/978-3-031-14714-2},
	language = {en},
	urldate = {2025-02-08},
	publisher = {Springer International Publishing},
	editor = {Rudolph, Günter and Kononova, Anna V. and Aguirre, Hernán and Kerschke, Pascal and Ochoa, Gabriela and Tušar, Tea},
	year = {2022},
	doi = {10.1007/978-3-031-14714-2},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\2UC985GQ\\Rudolph et al. - 2022 - Parallel Problem Solving from Nature – PPSN XVII 17th International Conference, PPSN 2022, Dortmund.pdf:application/pdf},
}

@article{misitano_towards_2022,
	title = {Towards explainable interactive multiobjective optimization: {R}-{XIMO}},
	volume = {36},
	issn = {1387-2532, 1573-7454},
	shorttitle = {Towards explainable interactive multiobjective optimization},
	url = {https://link.springer.com/10.1007/s10458-022-09577-3},
	doi = {10.1007/s10458-022-09577-3},
	abstract = {In interactive multiobjective optimization methods, the preferences of a decision maker are incorporated in a solution process to find solutions of interest for problems with multiple conflicting objectives. Since multiple solutions exist for these problems with various trade-offs, preferences are crucial to identify the best solution(s). However, it is not necessarily clear to the decision maker how the preferences lead to particular solutions and, by introducing explanations to interactive multiobjective optimization methods, we promote a novel paradigm of explainable interactive multiobjective optimization. As a proof of concept, we introduce a new method, R-XIMO, which provides explanations to a decision maker for reference point based interactive methods. We utilize concepts of explainable artificial intelligence and SHAP (Shapley Additive exPlanations) values. R-XIMO allows the decision maker to learn about the trade-offs in the underlying problem and promotes confidence in the solutions found. In particular, R-XIMO supports the decision maker in expressing new preferences that help them improve a desired objective by suggesting another objective to be impaired. This kind of support has been lacking. We validate R-XIMO numerically, with an illustrative example, and with a case study demonstrating how R-XIMO can support a real decision maker. Our results show that R-XIMO successfully generates sound explanations. Thus, incorporating explainability in interactive methods appears to be a very promising and exciting new research area.},
	language = {en},
	number = {2},
	urldate = {2025-02-08},
	journal = {Autonomous Agents and Multi-Agent Systems},
	author = {Misitano, Giovanni and Afsar, Bekir and Lárraga, Giomara and Miettinen, Kaisa},
	month = oct,
	year = {2022},
	pages = {43},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\QJ8Y2MNZ\\Misitano et al. - 2022 - Towards explainable interactive multiobjective optimization R-XIMO.pdf:application/pdf},
}

@article{hunter_introduction_2019,
	title = {An {Introduction} to {Multiobjective} {Simulation} {Optimization}},
	volume = {29},
	issn = {1049-3301, 1558-1195},
	url = {https://dl.acm.org/doi/10.1145/3299872},
	doi = {10.1145/3299872},
	abstract = {The multiobjective simulation optimization (MOSO) problem is a nonlinear multiobjective optimization problem in which multiple simultaneous and conflicting objective functions can only be observed with stochastic error. We provide an introduction to MOSO at the advanced tutorial level, aimed at researchers and practitioners who wish to begin working in this emerging area. Our focus is exclusively on MOSO methods that characterize the entire efficient or Pareto-optimal set as the solution to the MOSO problem; later, this set may be used as input to the broader multicriteria decision-making process. Our introduction to MOSO includes an overview of existing theory, methods, and provably convergent algorithms that explicitly control sampling error for (1) MOSO on finite sets, called multiobjective ranking and selection; (2) MOSO with integer-ordered decision variables; and (3) MOSO with continuous decision variables. In the context of integer-ordered and continuous decision variables, we focus on methods that provably converge to a local efficient set under the natural ordering. We also discuss key open questions that remain in this emerging field.},
	language = {en},
	number = {1},
	urldate = {2025-02-08},
	journal = {ACM Transactions on Modeling and Computer Simulation},
	author = {Hunter, Susan R. and Applegate, Eric A. and Arora, Viplove and Chong, Bryan and Cooper, Kyle and Rincón-Guevara, Oscar and Vivas-Valencia, Carolina},
	month = jan,
	year = {2019},
	pages = {1--36},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\4F398E4P\\Hunter et al. - 2019 - An Introduction to Multiobjective Simulation Optimization.pdf:application/pdf},
}

@article{lu_neural_2024,
	title = {Neural {Architecture} {Search} as {Multiobjective} {Optimization} {Benchmarks}: {Problem} {Formulation} and {Performance} {Assessment}},
	volume = {28},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1089-778X, 1089-778X, 1941-0026},
	shorttitle = {Neural {Architecture} {Search} as {Multiobjective} {Optimization} {Benchmarks}},
	url = {https://ieeexplore.ieee.org/document/10004638/},
	doi = {10.1109/TEVC.2022.3233364},
	abstract = {OF NOTATIONS six representative MOEAs (NSGA-II, MOEA/D, IBEA, NSGA-III, HypE, and RVEA). In the remainder of this article, ﬁrst, we provide necessary background information in Section II; second, we provide formal NAS problem formulation and analysis in Section III; third, we explain the design principles of our benchmark and test suite generation in Sections IV and V, respectively; fourth, we provide empirical evaluations in Section VI; and ﬁnally, conclusions and future studies are discussed in Section VII.},
	language = {en},
	number = {2},
	urldate = {2025-02-08},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Lu, Zhichao and Cheng, Ran and Jin, Yaochu and Tan, Kay Chen and Deb, Kalyanmoy},
	month = apr,
	year = {2024},
	pages = {323--337},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\GKK2ESNJ\\Lu et al. - 2024 - Neural Architecture Search as Multiobjective Optimization Benchmarks Problem Formulation and Perfor.pdf:application/pdf},
}

@misc{pfisterer_yahpo_2022,
	title = {{YAHPO} {Gym} -- {An} {Efficient} {Multi}-{Objective} {Multi}-{Fidelity} {Benchmark} for {Hyperparameter} {Optimization}},
	url = {http://arxiv.org/abs/2109.03670},
	doi = {10.48550/arXiv.2109.03670},
	abstract = {When developing and analyzing new hyperparameter optimization methods, it is vital to empirically evaluate and compare them on well-curated benchmark suites. In this work, we propose a new set of challenging and relevant benchmark problems motivated by desirable properties and requirements for such benchmarks. Our new surrogate-based benchmark collection consists of 14 scenarios that in total constitute over 700 multi- delity hyperparameter optimization problems, which all enable multi-objective hyperparameter optimization. Furthermore, we empirically compare surrogate-based benchmarks to the more widelyused tabular benchmarks, and demonstrate that the latter may produce unfaithful results regarding the performance ranking of HPO methods. We examine and compare our benchmark collection with respect to de ned requirements and propose a single-objective as well as a multi-objective benchmark suite on which we compare 7 single-objective and 7 multi-objective optimizers in a benchmark experiment. Our software is available at [https://github.com/slds-lmu/yahpo\_gym].},
	language = {en},
	urldate = {2025-02-08},
	publisher = {arXiv},
	author = {Pfisterer, Florian and Schneider, Lennart and Moosbauer, Julia and Binder, Martin and Bischl, Bernd},
	month = jul,
	year = {2022},
	note = {arXiv:2109.03670 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Accepted at the First Conference on Automated Machine Learning (Main Track). 39 pages, 12 tables, 10 figures, 1 listing},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\ADNUS8CZ\\Pfisterer et al. - 2022 - YAHPO Gym -- An Efficient Multi-Objective Multi-Fidelity Benchmark for Hyperparameter Optimization.pdf:application/pdf},
}

@misc{eggensperger_hpobench_2022,
	title = {{HPOBench}: {A} {Collection} of {Reproducible} {Multi}-{Fidelity} {Benchmark} {Problems} for {HPO}},
	shorttitle = {{HPOBench}},
	url = {http://arxiv.org/abs/2109.06716},
	doi = {10.48550/arXiv.2109.06716},
	abstract = {To achieve peak predictive performance, hyperparameter optimization (HPO) is a crucial component of machine learning and its applications. Over the last years, the number of efﬁcient algorithms and tools for HPO grew substantially. At the same time, the community is still lacking realistic, diverse, computationally cheap, and standardized benchmarks. This is especially the case for multi-ﬁdelity HPO methods. To close this gap, we propose HPOBench, which includes 7 existing and 5 new benchmark families, with a total of more than 100 multiﬁdelity benchmark problems. HPOBench allows to run this extendable set of multi-ﬁdelity HPO benchmarks in a reproducible way by isolating and packaging the individual benchmarks in containers. It also provides surrogate and tabular benchmarks for computationally affordable yet statistically sound evaluations. To demonstrate HPOBench’s broad compatibility with various optimization tools, as well as its usefulness, we conduct an exemplary large-scale study evaluating 13 optimizers from 6 optimization tools. We provide HPOBench here: https: //github.com/automl/HPOBench.},
	language = {en},
	urldate = {2025-02-08},
	publisher = {arXiv},
	author = {Eggensperger, Katharina and Müller, Philipp and Mallik, Neeratyoy and Feurer, Matthias and Sass, René and Klein, Aaron and Awad, Noor and Lindauer, Marius and Hutter, Frank},
	month = oct,
	year = {2022},
	note = {arXiv:2109.06716 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Published at NeurIPS Datasets and Benchmarks Track 2021. Updated version},
	annote = {Comment: Published at NeurIPS Datasets and Benchmarks Track 2021. Updated version},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\TKEEQTVW\\Eggensperger et al. - 2022 - HPOBench A Collection of Reproducible Multi-Fidelity Benchmark Problems for HPO.pdf:application/pdf},
}

@misc{elsken_efficient_2019,
	title = {Efficient {Multi}-objective {Neural} {Architecture} {Search} via {Lamarckian} {Evolution}},
	url = {http://arxiv.org/abs/1804.09081},
	doi = {10.48550/arXiv.1804.09081},
	abstract = {Neural Architecture Search aims at automatically ﬁnding neural network architectures that are competitive with architectures designed by human experts. While recent approaches have achieved state-of-the-art predictive performance for, e.g., image recognition, they are problematic under resource constraints for two reasons: (1) the neural architectures found are solely optimized for high predictive performance, without penalizing excessive resource consumption; (2) most architecture search methods require vast computational resources. We address the ﬁrst shortcoming by proposing LEMONADE, an evolutionary algorithm for multi-objective architecture search that allows approximating the entire Pareto front of architectures under multiple objectives, such as predictive performance and number of parameters, in a single run of the method. We address the second shortcoming by proposing a Lamarckian inheritance mechanism for LEMONADE which generates child networks that are warm started with the predictive performance of their trained parents. This is accomplished by using (approximate) network morphism operators for generating children. The combination of these two contributions allows ﬁnding models that are on par or even outperform both hand-crafted as well as automatically-designed networks.},
	language = {en},
	urldate = {2025-02-08},
	publisher = {arXiv},
	author = {Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
	month = feb,
	year = {2019},
	note = {arXiv:1804.09081 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Published as a conference paper at ICLR, International Conference on Learning Representations, 2019},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\AGF3S69H\\Elsken et al. - 2019 - Efficient Multi-objective Neural Architecture Search via Lamarckian Evolution.pdf:application/pdf},
}

@misc{ying_nas-bench-101_2019,
	title = {{NAS}-{Bench}-101: {Towards} {Reproducible} {Neural} {Architecture} {Search}},
	shorttitle = {{NAS}-{Bench}-101},
	url = {http://arxiv.org/abs/1902.09635},
	doi = {10.48550/arXiv.1902.09635},
	abstract = {Recent advances in neural architecture search (NAS) demand tremendous computational resources, which makes it difﬁcult to reproduce experiments and imposes a barrier-to-entry to researchers without access to large-scale computation. We aim to ameliorate these problems by introducing NAS-Bench-101, the ﬁrst public architecture dataset for NAS research. To build NASBench-101, we carefully constructed a compact, yet expressive, search space, exploiting graph isomorphisms to identify 423k unique convolutional architectures. We trained and evaluated all of these architectures multiple times on CIFAR-10 and compiled the results into a large dataset of over 5 million trained models. This allows researchers to evaluate the quality of a diverse range of models in milliseconds by querying the precomputed dataset. We demonstrate its utility by analyzing the dataset as a whole and by benchmarking a range of architecture optimization algorithms.},
	language = {en},
	urldate = {2025-02-08},
	publisher = {arXiv},
	author = {Ying, Chris and Klein, Aaron and Real, Esteban and Christiansen, Eric and Murphy, Kevin and Hutter, Frank},
	month = may,
	year = {2019},
	note = {arXiv:1902.09635 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Published in the Proceedings of the 36th International Conference on Machine Learning},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\4XBEQ8SE\\Ying et al. - 2019 - NAS-Bench-101 Towards Reproducible Neural Architecture Search.pdf:application/pdf},
}

@misc{zela_nas-bench-1shot1_2020,
	title = {{NAS}-{Bench}-{1Shot1}: {Benchmarking} and {Dissecting} {One}-shot {Neural} {Architecture} {Search}},
	shorttitle = {{NAS}-{Bench}-{1Shot1}},
	url = {http://arxiv.org/abs/2001.10422},
	doi = {10.48550/arXiv.2001.10422},
	abstract = {One-shot neural architecture search (NAS) has played a crucial role in making NAS methods computationally feasible in practice. Nevertheless, there is still a lack of understanding on how these weight-sharing algorithms exactly work due to the many factors controlling the dynamics of the process. In order to allow a scientiﬁc study of these components, we introduce a general framework for one-shot NAS that can be instantiated to many recently-introduced variants and introduce a general benchmarking framework that draws on the recent large-scale tabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot NAS methods. To showcase the framework, we compare several state-of-the-art one-shot NAS methods, examine how sensitive they are to their hyperparameters and how they can be improved by tuning their hyperparameters, and compare their performance to that of blackbox optimizers for NAS-Bench-101.},
	language = {en},
	urldate = {2025-02-08},
	publisher = {arXiv},
	author = {Zela, Arber and Siems, Julien and Hutter, Frank},
	month = apr,
	year = {2020},
	note = {arXiv:2001.10422 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: In: International Conference on Learning Representations (ICLR 2020); 19 pages, 17 figures},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\MUFFZ4ZC\\Zela et al. - 2020 - NAS-Bench-1Shot1 Benchmarking and Dissecting One-shot Neural Architecture Search.pdf:application/pdf},
}

@misc{snoek_practical_2012,
	title = {Practical {Bayesian} {Optimization} of {Machine} {Learning} {Algorithms}},
	url = {http://arxiv.org/abs/1206.2944},
	doi = {10.48550/arXiv.1206.2944},
	abstract = {Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a "black art" that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
	language = {en},
	urldate = {2025-02-08},
	publisher = {arXiv},
	author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
	month = aug,
	year = {2012},
	note = {arXiv:1206.2944 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\KAWHK6VA\\Snoek et al. - 2012 - Practical Bayesian Optimization of Machine Learning Algorithms.pdf:application/pdf},
}

@misc{belakaria_max-value_2020,
	title = {Max-value {Entropy} {Search} for {Multi}-{Objective} {Bayesian} {Optimization} with {Constraints}},
	url = {http://arxiv.org/abs/2009.01721},
	doi = {10.48550/arXiv.2009.01721},
	abstract = {We consider the problem of constrained multi-objective blackbox optimization using expensive function evaluations, where the goal is to approximate the true Pareto set of solutions satisfying a set of constraints while minimizing the number of function evaluations. For example, in aviation power system design applications, we need to ﬁnd the designs that trade-off total energy and the mass while satisfying speciﬁc thresholds for motor temperature and voltage of cells. This optimization requires performing expensive computational simulations to evaluate designs. In this paper, we propose a new approach referred to as Max-value Entropy Search for Multi-objective Optimization with Constraints (MESMOC) to solve this problem. MESMOC employs an output-space entropy based acquisition function to efﬁciently select the sequence of inputs for evaluation to uncover high-quality pareto-set solutions while satisfying constraints. We apply MESMOC to two real-world engineering design applications to demonstrate its effectiveness.},
	language = {en},
	urldate = {2025-02-08},
	publisher = {arXiv},
	author = {Belakaria, Syrine and Deshwal, Aryan and Doppa, Janardhan Rao},
	month = nov,
	year = {2020},
	note = {arXiv:2009.01721 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: 2 figure, 1 table. arXiv admin note: text overlap with arXiv:2008.07029},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\D9N8896U\\Belakaria et al. - 2020 - Max-value Entropy Search for Multi-Objective Bayesian Optimization with Constraints.pdf:application/pdf},
}

@misc{hernandez-lobato_predictive_2016,
	title = {Predictive {Entropy} {Search} for {Multi}-objective {Bayesian} {Optimization}},
	url = {http://arxiv.org/abs/1511.05467},
	doi = {10.48550/arXiv.1511.05467},
	abstract = {We present PESMO, a Bayesian method for identifying the Pareto set of multi-objective optimization problems, when the functions are expensive to evaluate. The central idea of PESMO is to choose evaluation points so as to maximally reduce the entropy of the posterior distribution over the Pareto set. Critically, the PESMO multi-objective acquisition function can be decomposed as a sum of objectivespeciﬁc acquisition functions, which enables the algorithm to be used in decoupled scenarios in which the objectives can be evaluated separately and perhaps with different costs. This decoupling capability also makes it possible to identify difﬁcult objectives that require more evaluations. PESMO also offers gains in efﬁciency, as its cost scales linearly with the number of objectives, in comparison to the exponential cost of other methods. We compare PESMO with other related methods for multi-objective Bayesian optimization on synthetic and real-world problems. The results show that PESMO produces better recommendations with a smaller number of evaluations of the objectives, and that a decoupled evaluation can lead to improvements in performance, particularly when the number of objectives is large.},
	language = {en},
	urldate = {2025-02-08},
	publisher = {arXiv},
	author = {Hernández-Lobato, Daniel and Hernández-Lobato, José Miguel and Shah, Amar and Adams, Ryan P.},
	month = feb,
	year = {2016},
	note = {arXiv:1511.05467 [stat]},
	keywords = {Statistics - Machine Learning},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\TG9X7BES\\Hernández-Lobato et al. - 2016 - Predictive Entropy Search for Multi-objective Bayesian Optimization.pdf:application/pdf},
}

@article{deighan_genetic-algorithm-optimized_2021,
	title = {Genetic-algorithm-optimized neural networks for gravitational wave classification},
	volume = {33},
	issn = {0941-0643, 1433-3058},
	url = {https://link.springer.com/10.1007/s00521-021-06024-4},
	doi = {10.1007/s00521-021-06024-4},
	abstract = {Gravitational-wave detection strategies are based on a signal analysis technique known as matched ﬁltering. Despite the success of matched ﬁltering, due to its computational cost, there has been recent interest in developing deep convolutional neural networks (CNNs) for signal detection. Designing these networks remains a challenge as most procedures adopt a trial and error strategy to set the hyperparameter values. We propose a new method for hyperparameter optimization based on genetic algorithms (GAs). We compare six different GA variants and explore different choices for the GA-optimized ﬁtness score. We show that the GA can discover high-quality architectures when the initial hyperparameter seed values are far from a good solution as well as reﬁning already good networks. For example, when starting from the architecture proposed by George and Huerta, the network optimized over the 20-dimensional hyperparameter space has 78\% fewer trainable parameters while obtaining an 11\% increase in accuracy for our test problem. Using genetic algorithm optimization to reﬁne an existing network should be especially useful if the problem context (e.g., statistical properties of the noise, signal model, etc) changes and one needs to rebuild a network. In all of our experiments, we ﬁnd the GA discovers signiﬁcantly less complicated networks as compared to the seed network, suggesting it can be used to prune wasteful network structures. While we have restricted our attention to CNN classiﬁers, our GA hyperparameter optimization strategy can be applied within other machine learning settings.},
	language = {en},
	number = {20},
	urldate = {2025-02-08},
	journal = {Neural Computing and Applications},
	author = {Deighan, Dwyer S. and Field, Scott E. and Capano, Collin D. and Khanna, Gaurav},
	month = oct,
	year = {2021},
	pages = {13859--13883},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\R993GIU9\\Deighan et al. - 2021 - Genetic-algorithm-optimized neural networks for gravitational wave classification.pdf:application/pdf},
}

@inproceedings{juang_structure_2014,
	address = {Beijing, China},
	title = {Structure and parameter optimization of {FNNs} using multi-objective {ACO} for control and prediction},
	isbn = {978-1-4799-2072-3 978-1-4799-2073-0},
	url = {https://ieeexplore.ieee.org/document/6891545},
	doi = {10.1109/FUZZ-IEEE.2014.6891545},
	language = {en},
	urldate = {2025-02-08},
	booktitle = {2014 {IEEE} {International} {Conference} on {Fuzzy} {Systems} ({FUZZ}-{IEEE})},
	publisher = {IEEE},
	author = {Juang, Chia-Feng and Hsu, Chia-Hung},
	month = jul,
	year = {2014},
	pages = {928--933},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\TPNDRVA5\\Juang and Hsu - 2014 - Structure and parameter optimization of FNNs using multi-objective ACO for control and prediction.pdf:application/pdf},
}

@article{rajagopal_deep_2020,
	title = {A {Deep} {Learning} {Model} {Based} on {Multi}-{Objective} {Particle} {Swarm} {Optimization} for {Scene} {Classification} in {Unmanned} {Aerial} {Vehicles}},
	volume = {8},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9146631/},
	doi = {10.1109/ACCESS.2020.3011502},
	abstract = {Recently, the increase in inexpensive and compact unmanned aerial vehicles (UAVs) and lightweight imaging sensors has led to an interest in using them in various remote sensing applications. The processes of collecting, calibrating, registering, and processing data from miniature UAVs and interpreting the data semantically are time-consuming. In UAV aerial imagery, learning effective image representations is central to the scene classiﬁcation process. Earlier approaches to the scene classiﬁcation process depended on feature coding methods with low-level hand-engineered features or unsupervised feature learning. These methods could produce mid-level image features with restricted representational abilities, which generally yielded mediocre results. The development of convolutional neural networks (CNNs) has made image classiﬁcation more efﬁcient. Due to the limited resources in UAVs, it is hard to ﬁne-tune the hyperparameters and the trade-offs between classiﬁer results and computation complexity. This paper introduces a new multi-objective optimization model for evolving state-of-the-art deep CNNs for scene classiﬁcation, which generates the non-dominant solutions in an automated way at the Pareto front. We use a set of two benchmark datasets to test the performance of the scene classiﬁcation model and make a detailed comparative study. The proposed method attains a very low computational time of 80 sec and maximum accuracy of 97.88\% compared to all other methods. The proposed method is found to be appropriate for the effective scene classiﬁcation of images captured by UAVs.},
	language = {en},
	urldate = {2025-02-08},
	journal = {IEEE Access},
	author = {Rajagopal, Aghila and Joshi, Gyanendra Prasad and Ramachandran, A. and Subhalakshmi, R. T. and Khari, Manju and Jha, Sudan and Shankar, K. and You, Jinsang},
	year = {2020},
	pages = {135383--135393},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\35RJKNL2\\Rajagopal et al. - 2020 - A Deep Learning Model Based on Multi-Objective Particle Swarm Optimization for Scene Classification.pdf:application/pdf},
}

@book{hutter_automated_2019,
	address = {Cham},
	series = {The {Springer} {Series} on {Challenges} in {Machine} {Learning}},
	title = {Automated {Machine} {Learning}: {Methods}, {Systems}, {Challenges}},
	copyright = {https://creativecommons.org/licenses/by/4.0},
	isbn = {978-3-030-05317-8 978-3-030-05318-5},
	shorttitle = {Automated {Machine} {Learning}},
	url = {http://link.springer.com/10.1007/978-3-030-05318-5},
	language = {en},
	urldate = {2025-02-08},
	publisher = {Springer International Publishing},
	editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
	year = {2019},
	doi = {10.1007/978-3-030-05318-5},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\6YAQ56S3\\Hutter et al. - 2019 - Automated Machine Learning Methods, Systems, Challenges.pdf:application/pdf},
}

@article{yang_hyperparameter_2020,
	title = {On {Hyperparameter} {Optimization} of {Machine} {Learning} {Algorithms}: {Theory} and {Practice}},
	volume = {415},
	issn = {09252312},
	shorttitle = {On {Hyperparameter} {Optimization} of {Machine} {Learning} {Algorithms}},
	url = {http://arxiv.org/abs/2007.15745},
	doi = {10.1016/j.neucom.2020.07.061},
	abstract = {Machine learning algorithms have been used widely in various applications and areas. To fit a machine learning model into different problems, its hyper-parameters must be tuned. Selecting the best hyper-parameter configuration for machine learning models has a direct impact on the model's performance. It often requires deep knowledge of machine learning algorithms and appropriate hyper-parameter optimization techniques. Although several automatic optimization techniques exist, they have different strengths and drawbacks when applied to different types of problems. In this paper, optimizing the hyper-parameters of common machine learning models is studied. We introduce several state-of-the-art optimization techniques and discuss how to apply them to machine learning algorithms. Many available libraries and frameworks developed for hyper-parameter optimization problems are provided, and some open challenges of hyper-parameter optimization research are also discussed in this paper. Moreover, experiments are conducted on benchmark datasets to compare the performance of different optimization methods and provide practical examples of hyper-parameter optimization. This survey paper will help industrial users, data analysts, and researchers to better develop machine learning models by identifying the proper hyper-parameter configurations effectively.},
	language = {en},
	urldate = {2025-02-08},
	journal = {Neurocomputing},
	author = {Yang, Li and Shami, Abdallah},
	month = nov,
	year = {2020},
	note = {arXiv:2007.15745 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {295--316},
	annote = {Comment: Published in Neurocomputing (Elsevier's journal, Q1, IF: 5.779). Tutorial code has got 1000+ stars. Github link: https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\TEKPPRGF\\Yang and Shami - 2020 - On Hyperparameter Optimization of Machine Learning Algorithms Theory and Practice.pdf:application/pdf},
}

@article{he_automl_2021,
	title = {{AutoML}: {A} {Survey} of the {State}-of-the-{Art}},
	volume = {212},
	issn = {09507051},
	shorttitle = {{AutoML}},
	url = {http://arxiv.org/abs/1908.00709},
	doi = {10.1016/j.knosys.2020.106622},
	abstract = {Deep learning (DL) techniques have obtained remarkable achievements on various tasks, such as image recognition, object detection, and language modeling. However, building a high-quality DL system for a speciﬁc task highly relies on human expertise, hindering its wide application. Meanwhile, automated machine learning (AutoML) is a promising solution for building a DL system without human assistance and is being extensively studied. This paper presents a comprehensive and up-to-date review of the state-of-the-art (SOTA) in AutoML. According to the DL pipeline, we introduce AutoML methods –– covering data preparation, feature engineering, hyperparameter optimization, and neural architecture search (NAS) –– with a particular focus on NAS, as it is currently a hot sub-topic of AutoML. We summarize the representative NAS algorithms’ performance on the CIFAR-10 and ImageNet datasets and further discuss the following subjects of NAS methods: one/two-stage NAS, one-shot NAS, joint hyperparameter and architecture optimization, and resource-aware NAS. Finally, we discuss some open problems related to the existing AutoML methods for future research.},
	language = {en},
	urldate = {2025-02-08},
	journal = {Knowledge-Based Systems},
	author = {He, Xin and Zhao, Kaiyong and Chu, Xiaowen},
	month = jan,
	year = {2021},
	note = {arXiv:1908.00709 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	pages = {106622},
	annote = {Comment: automated machine learning (AutoML), published in journal of Knowledge-Based Systems},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\VPZZGMQI\\He et al. - 2021 - AutoML A Survey of the State-of-the-Art.pdf:application/pdf},
}

@inproceedings{zhang_automated_2021,
	address = {Montreal, Canada},
	title = {Automated {Machine} {Learning} on {Graphs}: {A} {Survey}},
	isbn = {978-0-9992411-9-6},
	shorttitle = {Automated {Machine} {Learning} on {Graphs}},
	url = {https://www.ijcai.org/proceedings/2021/637},
	doi = {10.24963/ijcai.2021/637},
	abstract = {Machine learning on graphs has been extensively studied in both academic and industry. However, as the literature on graph learning booms with a vast number of emerging methods and techniques, it becomes increasingly difﬁcult to manually design the optimal machine learning algorithm for different graph-related tasks. To solve this critical challenge, automated machine learning (AutoML) on graphs which combines the strength of graph machine learning and AutoML together, is gaining attention from the research community. Therefore, we comprehensively survey AutoML on graphs in this paper, primarily focusing on hyper-parameter optimization (HPO) and neural architecture search (NAS) for graph machine learning. We further overview libraries related to automated graph machine learning and in-depth discuss AutoGL, the ﬁrst dedicated open-source library for AutoML on graphs. In the end, we share our insights on future research directions for automated graph machine learning. This paper is the ﬁrst systematic and comprehensive review of automated machine learning on graphs to the best of our knowledge.},
	language = {en},
	urldate = {2025-02-08},
	booktitle = {Proceedings of the {Thirtieth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Zhang, Ziwei and Wang, Xin and Zhu, Wenwu},
	month = aug,
	year = {2021},
	pages = {4704--4712},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\GY2GPK6S\\Zhang et al. - 2021 - Automated Machine Learning on Graphs A Survey.pdf:application/pdf},
}

@article{baydin_automatic_nodate,
	title = {Automatic differentiation in machine learning},
	abstract = {Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic diﬀerentiation (AD), also called algorithmic diﬀerentiation or simply “autodiﬀ”, is a family of techniques similar to but more general than backpropagation for eﬃciently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established ﬁeld with applications in areas including computational ﬂuid dynamics, atmospheric sciences, and engineering design optimization. Until very recently, the ﬁelds of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other’s results. Despite its relevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names “dynamic computational graphs” and “diﬀerentiable programming”. We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main implementation techniques. By precisely deﬁning the main diﬀerentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms “autodiﬀ”, “automatic diﬀerentiation”, and “symbolic diﬀerentiation” as these are encountered more and more in machine learning settings.},
	language = {en},
	author = {Baydin, Atılım Gunes and Pearlmutter, Barak A and Radul, Alexey Andreyevich and Siskind, Jeﬀrey Mark},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\TDJXXPYQ\\Baydin et al. - Automatic differentiation in machine learning.pdf:application/pdf},
}

@article{feurer_efficient_nodate,
	title = {Efficient and {Robust} {Automated} {Machine} {Learning}},
	abstract = {The success of machine learning in a broad range of applications has led to an ever-growing demand for machine learning systems that can be used off the shelf by non-experts. To be effective in practice, such systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand, and also set their respective hyperparameters. Recent work has started to tackle this automated machine learning (AutoML) problem with the help of efﬁcient Bayesian optimization methods. Building on this, we introduce a robust new AutoML system based on scikit-learn (using 15 classiﬁers, 14 feature preprocessing methods, and 4 data preprocessing methods, giving rise to a structured hypothesis space with 110 hyperparameters). This system, which we dub AUTO-SKLEARN, improves on existing AutoML methods by automatically taking into account past performance on similar datasets, and by constructing ensembles from the models evaluated during the optimization. Our system won the ﬁrst phase of the ongoing ChaLearn AutoML challenge, and our comprehensive analysis on over 100 diverse datasets shows that it substantially outperforms the previous state of the art in AutoML. We also demonstrate the performance gains due to each of our contributions and derive insights into the effectiveness of the individual components of AUTO-SKLEARN.},
	language = {en},
	author = {Feurer, Matthias and Klein, Aaron and Eggensperger, Katharina and Springenberg, Jost and Blum, Manuel and Hutter, Frank},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\3WDPJIYQ\\Feurer et al. - Efficient and Robust Automated Machine Learning.pdf:application/pdf},
}

@misc{gardner_gpytorch_2021,
	title = {{GPyTorch}: {Blackbox} {Matrix}-{Matrix} {Gaussian} {Process} {Inference} with {GPU} {Acceleration}},
	shorttitle = {{GPyTorch}},
	url = {http://arxiv.org/abs/1809.11165},
	doi = {10.48550/arXiv.1809.11165},
	abstract = {Despite advances in scalable models, the inference tools used for Gaussian processes (GPs) have yet to fully capitalize on developments in computing hardware. We present an efﬁcient and general approach to GP inference based on Blackbox Matrix-Matrix multiplication (BBMM). BBMM inference uses a modiﬁed batched version of the conjugate gradients algorithm to derive all terms for training and inference in a single call. BBMM reduces the asymptotic complexity of exact GP inference from O(n3) to O(n2). Adapting this algorithm to scalable approximations and complex GP models simply requires a routine for efﬁcient matrix-matrix multiplication with the kernel and its derivative. In addition, BBMM uses a specialized preconditioner to substantially speed up convergence. In experiments we show that BBMM effectively uses GPU hardware to dramatically accelerate both exact GP inference and scalable approximations. Additionally, we provide GPyTorch, a software platform for scalable GP inference via BBMM, built on PyTorch.},
	language = {en},
	urldate = {2025-02-08},
	publisher = {arXiv},
	author = {Gardner, Jacob R. and Pleiss, Geoff and Bindel, David and Weinberger, Kilian Q. and Wilson, Andrew Gordon},
	month = jun,
	year = {2021},
	note = {arXiv:1809.11165 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: NeurIPS 2018. Most recent version includes additional details on preconditioned BBMM},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\HVWI7QRY\\Gardner et al. - 2021 - GPyTorch Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration.pdf:application/pdf},
}

@misc{noauthor_uberbayesmark_2025,
	title = {uber/bayesmark},
	copyright = {Apache-2.0},
	url = {https://github.com/uber/bayesmark},
	abstract = {Benchmark framework to easily compare Bayesian optimization methods on real machine learning tasks},
	urldate = {2025-02-11},
	publisher = {Uber Open Source},
	month = feb,
	year = {2025},
	note = {original-date: 2019-07-26T17:41:20Z},
	keywords = {bayesian-optimization, benchmark-framework, machine-learning, sklearn},
}

@article{schmucker_multi-objective_nodate,
	title = {Multi-{Objective} {Multi}-{Fidelity} {Hyperparameter} {Optimization} with {Application} to {Fairness}},
	abstract = {In many real-world applications, the performance of machine learning models is evaluated not along a single objective, but across multiple, potentially competing ones. For instance, for a model deciding whether to grant or deny loans, it is critical to make sure decisions are fair and not only accurate. As it is often infeasible to ﬁnd a single model performing best across all objectives, practitioners are forced to ﬁnd a trade-off between the individual objectives. While several multi-objective optimization (MO) techniques have been proposed in the machine learning literature (and beyond), little effort has been put towards using MO for hyperparameter optimization (HPO) problems; a task that has gained immense relevance and adoption in recent years. In this paper, we evaluate the suitability of existing MO algorithms for HPO and propose a novel multi-ﬁdelity method for this problem. We evaluate our approach on public datasets with a special emphasis on fairness-motivated applications, and report substantially lower wall-clock times when approximating Pareto frontiers compared to the state-of-the-art.},
	language = {en},
	author = {Schmucker, Robin and Donini, Michele and Perrone, Valerio and Zafar, Muhammad Bilal and Archambeau, Cédric},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\9HW6AKCV\\Schmucker et al. - Multi-Objective Multi-Fidelity Hyperparameter Optimization with Application to Fairness.pdf:application/pdf},
}

@article{perrone_scalable_nodate,
	title = {Scalable {Hyperparameter} {Transfer} {Learning}},
	abstract = {Bayesian optimization (BO) is a model-based approach for gradient-free black-box function optimization, such as hyperparameter optimization. Typically, BO relies on conventional Gaussian process (GP) regression, whose algorithmic complexity is cubic in the number of evaluations. As a result, GP-based BO cannot leverage large numbers of past function evaluations, for example, to warm-start related BO runs. We propose a multi-task adaptive Bayesian linear regression model for transfer learning in BO, whose complexity is linear in the function evaluations: one Bayesian linear regression model is associated to each black-box function optimization problem (or task), while transfer learning is achieved by coupling the models through a shared deep neural net. Experiments show that the neural net learns a representation suitable for warm-starting the black-box optimization problems and that BO runs can be accelerated when the target black-box function (e.g., validation loss) is learned together with other related signals (e.g., training loss). The proposed method was found to be at least one order of magnitude faster than competing methods recently published in the literature.},
	language = {en},
	author = {Perrone, Valerio and Jenatton, Rodolphe and Seeger, Matthias W and Archambeau, Cedric},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\A9ZN6G7F\\Perrone et al. - Scalable Hyperparameter Transfer Learning.pdf:application/pdf},
}

@article{parsa_bayesian_2020,
	title = {Bayesian {Multi}-objective {Hyperparameter} {Optimization} for {Accurate}, {Fast}, and {Efficient} {Neural} {Network} {Accelerator} {Design}},
	volume = {14},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/article/10.3389/fnins.2020.00667/full},
	doi = {10.3389/fnins.2020.00667},
	language = {en},
	urldate = {2025-02-11},
	journal = {Frontiers in Neuroscience},
	author = {Parsa, Maryam and Mitchell, John P. and Schuman, Catherine D. and Patton, Robert M. and Potok, Thomas E. and Roy, Kaushik},
	month = jul,
	year = {2020},
	pages = {667},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\U9CZLQJB\\Parsa et al. - 2020 - Bayesian Multi-objective Hyperparameter Optimization for Accurate, Fast, and Efficient Neural Networ.pdf:application/pdf},
}

@misc{liu_darts_2019,
	title = {{DARTS}: {Differentiable} {Architecture} {Search}},
	shorttitle = {{DARTS}},
	url = {http://arxiv.org/abs/1806.09055},
	doi = {10.48550/arXiv.1806.09055},
	abstract = {This paper addresses the scalability challenge of architecture search by formulating the task in a differentiable manner. Unlike conventional approaches of applying evolution or reinforcement learning over a discrete and non-differentiable search space, our method is based on the continuous relaxation of the architecture representation, allowing efﬁcient search of the architecture using gradient descent. Extensive experiments on CIFAR-10, ImageNet, Penn Treebank and WikiText-2 show that our algorithm excels in discovering high-performance convolutional architectures for image classiﬁcation and recurrent architectures for language modeling, while being orders of magnitude faster than state-of-the-art non-differentiable techniques. Our implementation has been made publicly available to facilitate further research on efﬁcient architecture search algorithms.},
	language = {en},
	urldate = {2025-02-11},
	publisher = {arXiv},
	author = {Liu, Hanxiao and Simonyan, Karen and Yang, Yiming},
	month = apr,
	year = {2019},
	note = {arXiv:1806.09055 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
	annote = {Comment: Published at ICLR 2019; Code and pretrained models available at https://github.com/quark0/darts},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\J3RS49ZY\\Liu et al. - 2019 - DARTS Differentiable Architecture Search.pdf:application/pdf},
}

@misc{arango_hpo-b_2021,
	title = {{HPO}-{B}: {A} {Large}-{Scale} {Reproducible} {Benchmark} for {Black}-{Box} {HPO} based on {OpenML}},
	shorttitle = {{HPO}-{B}},
	url = {http://arxiv.org/abs/2106.06257},
	doi = {10.48550/arXiv.2106.06257},
	abstract = {Hyperparameter optimization (HPO) is a core problem for the machine learning community and remains largely unsolved due to the signiﬁcant computational resources required to evaluate hyperparameter conﬁgurations. As a result, a series of recent related works have focused on the direction of transfer learning for quickly ﬁne-tuning hyperparameters on a dataset. Unfortunately, the community does not have a common large-scale benchmark for comparing HPO algorithms. Instead, the de facto practice consists of empirical protocols on arbitrary small-scale meta-datasets that vary inconsistently across publications, making reproducibility a challenge. To resolve this major bottleneck and enable a fair and fast comparison of black-box HPO methods on a level playing ﬁeld, we propose HPO-B, a new large-scale benchmark in the form of a collection of meta-datasets. Our benchmark is assembled and preprocessed from the OpenML repository and consists of 176 search spaces (algorithms) evaluated sparsely on 196 datasets with a total of 6.4 million hyperparameter evaluations. For ensuring reproducibility on our benchmark, we detail explicit experimental protocols, splits, and evaluation measures for comparing methods for both non-transfer, as well as, transfer learning HPO.},
	language = {en},
	urldate = {2025-02-11},
	publisher = {arXiv},
	author = {Arango, Sebastian Pineda and Jomaa, Hadi S. and Wistuba, Martin and Grabocka, Josif},
	month = oct,
	year = {2021},
	note = {arXiv:2106.06257 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: 10 pages},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\BXGQW8Z4\\Arango et al. - 2021 - HPO-B A Large-Scale Reproducible Benchmark for Black-Box HPO based on OpenML.pdf:application/pdf},
}

@inproceedings{mersmann_benchmarking_2010,
	address = {Barcelona, Spain},
	title = {Benchmarking evolutionary multiobjective optimization algorithms},
	isbn = {978-1-4244-6909-3},
	url = {http://ieeexplore.ieee.org/document/5586241/},
	doi = {10.1109/CEC.2010.5586241},
	abstract = {Choosing and tuning an optimization procedure for a given class of nonlinear optimization problems is not an easy task. One way to proceed is to consider this as a tournament, where each procedure will compete in different ‘disciplines’. Here, disciplines could either be different functions, which we want to optimize, or speciﬁc performance measures of the optimization procedure. We would then be interested in the algorithm that performs best in a majority of cases or whose average performance is maximal.},
	language = {en},
	urldate = {2025-02-11},
	booktitle = {{IEEE} {Congress} on {Evolutionary} {Computation}},
	publisher = {IEEE},
	author = {Mersmann, Olaf and Trautmann, Heike and Naujoks, Boris and Weihs, Claus},
	month = jul,
	year = {2010},
	pages = {1--8},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\89AZTM9I\\Mersmann et al. - 2010 - Benchmarking evolutionary multiobjective optimization algorithms.pdf:application/pdf},
}

@misc{lindauer_towards_2019,
	title = {Towards {Assessing} the {Impact} of {Bayesian} {Optimization}'s {Own} {Hyperparameters}},
	url = {http://arxiv.org/abs/1908.06674},
	doi = {10.48550/arXiv.1908.06674},
	abstract = {Bayesian Optimization (BO) is a common approach for hyperparameter optimization (HPO) in automated machine learning. Although it is well-accepted that HPO is crucial to obtain wellperforming machine learning models, tuning BO’s own hyperparameters is often neglected. In this paper, we empirically study the impact of optimizing BO’s own hyperparameters and the transferability of the found settings using a wide range of benchmarks, including artiﬁcial functions, HPO and HPO combined with neural architecture search. In particular, we show (i) that tuning can improve the any-time performance of different BO approaches, that optimized BO settings also perform well (ii) on similar problems and (iii) partially even on problems from other problem families, and (iv) which BO hyperparameters are most important.},
	language = {en},
	urldate = {2025-02-11},
	publisher = {arXiv},
	author = {Lindauer, Marius and Feurer, Matthias and Eggensperger, Katharina and Biedenkapp, André and Hutter, Frank},
	month = aug,
	year = {2019},
	note = {arXiv:1908.06674 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: Accepted at DSO workshop (as part of IJCAI'19)},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\PWB8CXPW\\Lindauer et al. - 2019 - Towards Assessing the Impact of Bayesian Optimization's Own Hyperparameters.pdf:application/pdf},
}

@inproceedings{pfisterer_learning_2021,
	address = {Lille France},
	title = {Learning multiple defaults for machine learning algorithms},
	isbn = {978-1-4503-8351-6},
	url = {https://dl.acm.org/doi/10.1145/3449726.3459523},
	doi = {10.1145/3449726.3459523},
	abstract = {Modern machine learning methods highly depend on their hyperparameter configurations for optimal performance. A widely used approach to selecting a configuration is using default settings, often proposed along with the publication of a new algorithm. Those default values are usually chosen in an ad-hoc manner to work on a wide variety of datasets. Different automatic hyperparameter configuration algorithms which select an optimal configuration per dataset have been proposed, but despite its importance, tuning is often skipped in applications because of additional run time, complexity, and experimental design questions. Instead, the learner is often applied in its defaults. This principled approach usually improves performance but adds additional algorithmic complexity and computational costs to the training procedure. We propose and study using a set of complementary default values, learned from a large database of prior empirical results as an alternative. Selecting an appropriate configuration on a new dataset then requires only a simple, efficient, and embarrassingly parallel search over this set. To demonstrate the effectiveness and efficiency of the approach, we compare learned sets of configurations to random search and Bayesian optimization. We show that sets of defaults can improve performance while being easy to deploy in comparison to more complex methods.},
	language = {en},
	urldate = {2025-02-11},
	booktitle = {Proceedings of the {Genetic} and {Evolutionary} {Computation} {Conference} {Companion}},
	publisher = {ACM},
	author = {Pfisterer, Florian and Van Rijn, Jan N. and Probst, Philipp and Müller, Andreas C. and Bischl, Bernd},
	month = jul,
	year = {2021},
	pages = {241--242},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\NTE2YS6Y\\Pfisterer et al. - 2021 - Learning multiple defaults for machine learning algorithms.pdf:application/pdf},
}

@inproceedings{wistuba_learning_2015,
	address = {Campus des Cordeliers, Paris, France},
	title = {Learning hyperparameter optimization initializations},
	isbn = {978-1-4673-8272-4},
	url = {http://ieeexplore.ieee.org/document/7344817/},
	doi = {10.1109/DSAA.2015.7344817},
	abstract = {Hyperparameter optimization is often done manually or by using a grid search. However, recent research has shown that automatic optimization techniques are able to accelerate this optimization process and ﬁnd hyperparameter conﬁgurations that lead to better models. Currently, transferring knowledge from previous experiments to a new experiment is of particular interest because it has been shown that it allows to further improve the hyperparameter optimization.},
	language = {en},
	urldate = {2025-02-11},
	booktitle = {2015 {IEEE} {International} {Conference} on {Data} {Science} and {Advanced} {Analytics} ({DSAA})},
	publisher = {IEEE},
	author = {Wistuba, Martin and Schilling, Nicolas and Schmidt-Thieme, Lars},
	month = oct,
	year = {2015},
	pages = {1--10},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\LKG2ISQ5\\Wistuba et al. - 2015 - Learning hyperparameter optimization initializations.pdf:application/pdf},
}

@misc{thornton_auto-weka_2013,
	title = {Auto-{WEKA}: {Combined} {Selection} and {Hyperparameter} {Optimization} of {Classification} {Algorithms}},
	shorttitle = {Auto-{WEKA}},
	url = {http://arxiv.org/abs/1208.3719},
	doi = {10.48550/arXiv.1208.3719},
	abstract = {Many diﬀerent machine learning algorithms exist; taking into account each algorithm’s hyperparameters, there is a staggeringly large number of possible alternatives overall. We consider the problem of simultaneously selecting a learning algorithm and setting its hyperparameters, going beyond previous work that addresses these issues in isolation. We show that this problem can be addressed by a fully automated approach, leveraging recent innovations in Bayesian optimization. Speciﬁcally, we consider a wide range of feature selection techniques (combining 3 search and 8 evaluator methods) and all classiﬁcation approaches implemented in WEKA, spanning 2 ensemble methods, 10 meta-methods, 27 base classiﬁers, and hyperparameter settings for each classiﬁer. On each of 21 popular datasets from the UCI repository, the KDD Cup 09, variants of the MNIST dataset and CIFAR-10, we show classiﬁcation performance often much better than using standard selection/hyperparameter optimization methods. We hope that our approach will help non-expert users to more eﬀectively identify machine learning algorithms and hyperparameter settings appropriate to their applications, and hence to achieve improved performance.},
	language = {en},
	urldate = {2025-02-11},
	publisher = {arXiv},
	author = {Thornton, Chris and Hutter, Frank and Hoos, Holger H. and Leyton-Brown, Kevin},
	month = mar,
	year = {2013},
	note = {arXiv:1208.3719 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: 9 pages, 3 figures},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\PG4F9Q7I\\Thornton et al. - 2013 - Auto-WEKA Combined Selection and Hyperparameter Optimization of Classification Algorithms.pdf:application/pdf},
}

@misc{zela_surrogate_2022,
	title = {Surrogate {NAS} {Benchmarks}: {Going} {Beyond} the {Limited} {Search} {Spaces} of {Tabular} {NAS} {Benchmarks}},
	shorttitle = {Surrogate {NAS} {Benchmarks}},
	url = {http://arxiv.org/abs/2008.09777},
	doi = {10.48550/arXiv.2008.09777},
	abstract = {The most signiﬁcant barrier to the advancement of Neural Architecture Search (NAS) is its demand for large computational resources, which hinders scientiﬁcally sound empirical evaluations of NAS methods. Tabular NAS benchmarks have alleviated this problem substantially, making it possible to properly evaluate NAS methods in seconds on commodity machines. However, an unintended consequence of tabular NAS benchmarks has been a focus on extremely small architectural search spaces since their construction relies on exhaustive evaluations of the space. This leads to unrealistic results that do not transfer to larger spaces. To overcome this fundamental limitation, we propose a methodology to create cheap NAS surrogate benchmarks for arbitrary search spaces. We exemplify this approach by creating surrogate NAS benchmarks on the existing tabular NAS-Bench-101 and on two widely used NAS search spaces with up to 1021 architectures (1013 times larger than any previous tabular NAS benchmark). We show that surrogate NAS benchmarks can model the true performance of architectures better than tabular benchmarks (at a small fraction of the cost), that they lead to faithful estimates of how well different NAS methods work on the original non-surrogate benchmark, and that they can generate new scientiﬁc insight. We open-source all our code and believe that surrogate NAS benchmarks are an indispensable tool to extend scientiﬁcally sound work on NAS to large and exciting search spaces.},
	language = {en},
	urldate = {2025-02-11},
	publisher = {arXiv},
	author = {Zela, Arber and Siems, Julien and Zimmer, Lucas and Lukasik, Jovita and Keuper, Margret and Hutter, Frank},
	month = apr,
	year = {2022},
	note = {arXiv:2008.09777 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\DIMMKGG3\\Zela et al. - 2022 - Surrogate NAS Benchmarks Going Beyond the Limited Search Spaces of Tabular NAS Benchmarks.pdf:application/pdf},
}

@article{ariafar_admmbo_2019,
	title = {{ADMMBO}: {Bayesian} {Optimization} with {Unknown} {Constraints} using {ADMM}},
	volume = {20},
	url = {http://jmlr.org/papers/v20/18-227.html},
	abstract = {There exist many problems in science and engineering that involve optimization of an unknown or partially unknown objective function. Recently, Bayesian Optimization (BO) has emerged as a powerful tool for solving optimization problems whose objective functions are only available as a black box and are expensive to evaluate. Many practical problems, however, involve optimization of an unknown objective function subject to unknown constraints. This is an important yet challenging problem for which, unlike optimizing an unknown function, existing methods face several limitations. In this paper, we present a novel constrained Bayesian optimization framework to optimize an unknown objective function subject to unknown constraints. We introduce an equivalent optimization by augmenting the objective function with constraints, introducing auxiliary variables for each constraint, and forcing the new variables to be equal to the main variable. Building on the Alternating Direction Method of Multipliers (ADMM) algorithm, we propose ADMM-Bayesian Optimization (ADMMBO) to solve the problem in an iterative fashion. Our framework leads to multiple unconstrained subproblems with unknown objective functions, which we then solve via BO. Our method resolves several challenges of state-of-the-art techniques: it can start from infeasible points, is insensitive to initialization, can eﬃciently handle ‘decoupled problems’ and has a concrete stopping criterion. Extensive experiments on a number of challenging BO benchmark problems show that our proposed approach outperforms the state-of-the-art methods in terms of the speed of obtaining a feasible solution and convergence to the global optimum as well as minimizing the number of total evaluations of unknown objective and constraints functions.},
	language = {en},
	number = {123},
	journal = {Journal of Machine Learning Research},
	author = {Ariafar, Setareh and Coll-Font, Jaume and Brooks, Dana},
	year = {2019},
	pages = {1--26},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\J2PIXNWD\\Ariafar et al. - ADMMBO Bayesian Optimization with Unknown Constraints using ADMM.pdf:application/pdf},
}

@article{eriksson_scalable_nodate,
	title = {Scalable {Constrained} {Bayesian} {Optimization}},
	abstract = {The global optimization of a high-dimensional black-box function under black-box constraints is a pervasive task in machine learning, control, and engineering. These problems are challenging since the feasible set is typically non-convex and hard to ﬁnd, in addition to the curses of dimensionality and the heterogeneity of the underlying functions. In particular, these characteristics dramatically impact the performance of Bayesian optimization methods, that otherwise have become the de facto standard for sample-eﬃcient optimization in unconstrained settings, leaving practitioners with evolutionary strategies or heuristics. We propose the scalable constrained Bayesian optimization (SCBO) algorithm that overcomes the above challenges and pushes the applicability of Bayesian optimization far beyond the state-of-the-art. A comprehensive experimental evaluation demonstrates that SCBO achieves excellent results on a variety of benchmarks. To this end, we propose two new control problems that we expect to be of independent value for the scientiﬁc community.},
	language = {en},
	author = {Eriksson, David and Poloczek, Matthias},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\VSQUUKCY\\Eriksson and Poloczek - Scalable Constrained Bayesian Optimization.pdf:application/pdf},
}

@misc{deshwal_bayesian_2021,
	title = {Bayesian {Optimization} over {Hybrid} {Spaces}},
	url = {http://arxiv.org/abs/2106.04682},
	doi = {10.48550/arXiv.2106.04682},
	abstract = {We consider the problem of optimizing hybrid structures (mixture of discrete and continuous input variables) via expensive black-box function evaluations. This problem arises in many realworld applications. For example, in materials design optimization via lab experiments, discrete and continuous variables correspond to the presence/absence of primitive elements and their relative concentrations respectively. The key challenge is to accurately model the complex interactions between discrete and continuous variables. In this paper, we propose a novel approach referred as Hybrid Bayesian Optimization (HyBO) by utilizing diffusion kernels, which are naturally deﬁned over continuous and discrete variables. We develop a principled approach for constructing diffusion kernels over hybrid spaces by utilizing the additive kernel formulation, which allows additive interactions of all orders in a tractable manner. We theoretically analyze the modeling strength of additive hybrid kernels and prove that it has the universal approximation property. Our experiments on synthetic and six diverse realworld benchmarks show that HyBO signiﬁcantly outperforms the state-of-the-art methods.},
	language = {en},
	urldate = {2025-02-13},
	publisher = {arXiv},
	author = {Deshwal, Aryan and Belakaria, Syrine and Doppa, Janardhan Rao},
	month = jun,
	year = {2021},
	note = {arXiv:2106.04682 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control, Computer Science - Artificial Intelligence},
	annote = {Comment: 14 pages, 18 figures},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\L9W65SDR\\Deshwal et al. - 2021 - Bayesian Optimization over Hybrid Spaces.pdf:application/pdf},
}

@article{eriksson_scalable_nodate-1,
	title = {Scalable {Global} {Optimization} via {Local} {Bayesian} {Optimization}},
	abstract = {Bayesian optimization has recently emerged as a popular method for the sampleefﬁcient optimization of expensive black-box functions. However, the application to high-dimensional problems with several thousand observations remains challenging, and on difﬁcult problems Bayesian optimization is often not competitive with other paradigms. In this paper we take the view that this is due to the implicit homogeneity of the global probabilistic models and an overemphasized exploration that results from global acquisition. This motivates the design of a local probabilistic approach for global optimization of large-scale high-dimensional problems. We propose the TuRBO algorithm that ﬁts a collection of local models and performs a principled global allocation of samples across these models via an implicit bandit approach. A comprehensive evaluation demonstrates that TuRBO outperforms stateof-the-art methods from machine learning and operations research on problems spanning reinforcement learning, robotics, and the natural sciences.},
	language = {en},
	author = {Eriksson, David and Pearce, Michael and Gardner, Jacob and Turner, Ryan D and Poloczek, Matthias},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\U4ESSCEF\\Eriksson et al. - Scalable Global Optimization via Local Bayesian Optimization.pdf:application/pdf},
}

@misc{brochu_tutorial_2010,
	title = {A {Tutorial} on {Bayesian} {Optimization} of {Expensive} {Cost} {Functions}, with {Application} to {Active} {User} {Modeling} and {Hierarchical} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1012.2599},
	doi = {10.48550/arXiv.1012.2599},
	abstract = {We present a tutorial on Bayesian optimization, a method of ﬁnding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to oﬀer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments—active user modelling with preferences, and hierarchical reinforcement learning—and a discussion of the pros and cons of Bayesian optimization based on our experiences.},
	language = {en},
	urldate = {2025-02-13},
	publisher = {arXiv},
	author = {Brochu, Eric and Cora, Vlad M. and Freitas, Nando de},
	month = dec,
	year = {2010},
	note = {arXiv:1012.2599 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\HFAEWXHV\\Brochu et al. - 2010 - A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Mod.pdf:application/pdf},
}

@article{kandasamy_tuning_nodate,
	title = {Tuning {Hyperparameters} without {Grad} {Students}: {Scalable} and {Robust} {Bayesian} {Optimisation} with {Dragonﬂy}},
	abstract = {Bayesian Optimisation (BO) refers to a suite of techniques for global optimisation of expensive black box functions, which use introspective Bayesian models of the function to efﬁciently search for the optimum. While BO has been applied successfully in many applications, modern optimisation tasks usher in new challenges where conventional methods fail spectacularly. In this work, we present Dragonﬂy, an open source Python library for scalable and robust BO. Dragonﬂy incorporates multiple recently developed methods that allow BO to be applied in challenging real world settings; these include better methods for handling higher dimensional domains, methods for handling multi-ﬁdelity evaluations when cheap approximations of an expensive function are available, methods for optimising over structured combinatorial spaces, such as the space of neural network architectures, and methods for handling parallel evaluations. Additionally, we develop new methodological improvements in BO for selecting the Bayesian model, selecting the acquisition function, and optimising over complex domains with different variable types and additional constraints. We compare Dragonﬂy to a suite of other packages and algorithms for global optimisation and demonstrate that when the above methods are integrated, they enable signiﬁcant improvements in the performance of BO. The Dragonﬂy library is available at dragonfly.github.io.},
	language = {en},
	author = {Kandasamy, Kirthevasan and Vysyaraju, Karun Raju and Neiswanger, Willie and Paria, Biswajit and Collins, Christopher R and Schneider, Jeff and Poczos, Barnabas and Xing, Eric P},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\RW6K9DBA\\Kandasamy et al. - Tuning Hyperparameters without Grad Students Scalable and Robust Bayesian Optimisation with Dragonﬂ.pdf:application/pdf},
}

@article{tiep_new_2024,
	title = {A {New} {Hyperparameter} {Tuning} {Framework} for {Regression} {Tasks} in {Deep} {Neural} {Network}: {Combined}-{Sampling} {Algorithm} to {Search} the {Optimized} {Hyperparameters}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2227-7390},
	shorttitle = {A {New} {Hyperparameter} {Tuning} {Framework} for {Regression} {Tasks} in {Deep} {Neural} {Network}},
	url = {https://www.mdpi.com/2227-7390/12/24/3892},
	doi = {10.3390/math12243892},
	abstract = {This paper introduces a novel hyperparameter optimization framework for regression tasks called the Combined-Sampling Algorithm to Search the Optimized Hyperparameters (CASOH). Our approach enables hyperparameter tuning for deep learning models with two hidden layers and multiple types of hyperparameters, enhancing the model’s capacity to work with complex optimization problems. The primary goal is to improve hyperparameter tuning performance in deep learning models compared to conventional methods such as Bayesian Optimization and Random Search. Furthermore, CASOH is evaluated alongside the state-of-the-art hyperparameter reinforcement learning (Hyp-RL) framework to ensure a comprehensive assessment. The CASOH framework integrates the Metropolis-Hastings algorithm with a uniform random sampling approach, increasing the likelihood of identifying promising hyperparameter configurations. Specifically, we developed a correlation between the objective function and samples, allowing subsequent samples to be strongly correlated with the current sample by applying an acceptance probability in our sampling algorithm. The effectiveness of our proposed method was examined using regression datasets such as Boston Housing, Critical heat flux (CHF), Concrete compressive strength, Combined Cycle Power Plant, Gas Turbine CO, and NOx Emission, as well as an ‘in-house’ dataset of lattice-physics parameters generated from a Monte Carlo code for nuclear fuel assembly simulation. One of the primary goals of this study is to construct an optimized deep-learning model capable of accurately predicting lattice-physics parameters for future applications of machine learning in nuclear reactor analysis. Our results indicate that this framework achieves competitive accuracy compared to conventional random search and Bayesian optimization methods. The most significant enhancement was observed in the lattice-physics dataset, achieving a 56.6\% improvement in prediction accuracy, compared to improvements of 53.2\% by Hyp-RL, 44.9\% by Bayesian optimization, and 38.8\% by random search relative to the nominal prediction. While the results are promising, further empirical validation across a broader range of datasets would be helpful to better assess the framework’s suitability for optimizing hyperparameters in complex problems involving high-dimensional parameters, highly non-linear systems, and multi-objective optimization tasks.},
	language = {en},
	number = {24},
	urldate = {2025-02-15},
	journal = {Mathematics},
	author = {Tiep, Nguyen Huu and Jeong, Hae-Yong and Kim, Kyung-Doo and Xuan Mung, Nguyen and Dao, Nhu-Ngoc and Tran, Hoai-Nam and Hoang, Van-Khanh and Ngoc Anh, Nguyen and Vu, Mai The},
	month = dec,
	year = {2024},
	pages = {3892},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\ZDJU35W7\\Tiep et al. - 2024 - A New Hyperparameter Tuning Framework for Regression Tasks in Deep Neural Network Combined-Sampling.pdf:application/pdf},
}

@article{kandasamy_gaussian_nodate,
	title = {Gaussian {Process} {Bandit} {Optimisation} with {Multi}-ﬁdelity {Evaluations}},
	abstract = {In many scientiﬁc and engineering applications, we are tasked with the optimisation of an expensive to evaluate black box function f . Traditional methods for this problem assume just the availability of this single function. However, in many cases, cheap approximations to f may be obtainable. For example, the expensive real world behaviour of a robot can be approximated by a cheap computer simulation. We can use these approximations to eliminate low function value regions cheaply and use the expensive evaluations of f in a small but promising region and speedily identify the optimum. We formalise this task as a multi-ﬁdelity bandit problem where the target function and its approximations are sampled from a Gaussian process. We develop MF-GP-UCB, a novel method based on upper conﬁdence bound techniques. In our theoretical analysis we demonstrate that it exhibits precisely the above behaviour, and achieves better regret than strategies which ignore multi-ﬁdelity information. MF-GP-UCB outperforms such naive strategies and other multi-ﬁdelity methods on several synthetic and real experiments.},
	language = {en},
	author = {Kandasamy, Kirthevasan and Dasarathy, Gautam and Oliva, Junier and Schneider, Jeff and Póczos, Barnabás},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\ZNLKM5E2\\Kandasamy et al. - Gaussian Process Bandit Optimisation with Multi-ﬁdelity Evaluations.pdf:application/pdf},
}

@misc{kandasamy_multi-fidelity_2017,
	title = {Multi-fidelity {Bayesian} {Optimisation} with {Continuous} {Approximations}},
	url = {http://arxiv.org/abs/1703.06240},
	doi = {10.48550/arXiv.1703.06240},
	abstract = {Bandit methods for black-box optimisation, such as Bayesian optimisation, are used in a variety of applications including hyper-parameter tuning and experiment design. Recently, multi-ﬁdelity methods have garnered considerable attention since function evaluations have become increasingly expensive in such applications. Multiﬁdelity methods use cheap approximations to the function of interest to speed up the overall optimisation process. However, most multi-ﬁdelity methods assume only a ﬁnite number of approximations. In many practical applications however, a continuous spectrum of approximations might be available. For instance, when tuning an expensive neural network, one might choose to approximate the cross validation performance using less data N and/or few training iterations T . Here, the approximations are best viewed as arising out of a continuous two dimensional space (N, T ). In this work, we develop a Bayesian optimisation method, BOCA, for this setting. We characterise its theoretical properties and show that it achieves better regret than than strategies which ignore the approximations. BOCA outperforms several other baselines in synthetic and real experiments.},
	language = {en},
	urldate = {2025-02-15},
	publisher = {arXiv},
	author = {Kandasamy, Kirthevasan and Dasarathy, Gautam and Schneider, Jeff and Poczos, Barnabas},
	month = mar,
	year = {2017},
	note = {arXiv:1703.06240 [stat]},
	keywords = {Statistics - Machine Learning},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\QGQFI6GR\\Kandasamy et al. - 2017 - Multi-fidelity Bayesian Optimisation with Continuous Approximations.pdf:application/pdf},
}

@article{amini_constrained_2025,
	title = {Constrained {Bayesian} {Optimization}: {A} {Review}},
	volume = {13},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	shorttitle = {Constrained {Bayesian} {Optimization}},
	url = {https://ieeexplore.ieee.org/document/10815962/},
	doi = {10.1109/ACCESS.2024.3522876},
	abstract = {Bayesian optimization is a sequential optimization method that is particularly well suited for problems with limited computational budgets involving expensive and non-convex black-box functions. Though it has been widely used to solve various optimization tasks, most of the literature has focused on unconstrained settings, while many real-world problems are characterized by constraints. This paper reviews the current literature on single-objective constrained Bayesian optimization, classifying it according to three main algorithmic aspects: (i) the metamodel, (ii) the acquisition function, and (iii) the identification procedure. We discuss the current methods in each of these categories and conclude by a discussion of real-world applications and highlighting the main shortcomings in the literature, providing some promising directions for future research.},
	language = {en},
	urldate = {2025-02-15},
	journal = {IEEE Access},
	author = {Amini, Sasan and Vannieuwenhuyse, Inneke and Morales-Hernández, Alejandro},
	year = {2025},
	pages = {1581--1593},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\G24876I4\\Amini et al. - 2025 - Constrained Bayesian Optimization A Review.pdf:application/pdf},
}

@article{upadhye_constrained_2024,
	title = {Constrained {Bayesian} {Optimization} with {Lower} {Confidence} {Bound}},
	volume = {66},
	issn = {0040-1706, 1537-2723},
	url = {https://www.tandfonline.com/doi/full/10.1080/00401706.2024.2336535},
	doi = {10.1080/00401706.2024.2336535},
	abstract = {In this article, we present a hybrid Bayesian optimization (BO) framework to solve constrained optimization problems by adopting a state-of-the-art acquisition function from the unconstrained BO literature, the well-known lower confidence bound acquisition function and propose a novel variant that analyzes the feasible and infeasible regions which ensure the theoretical convergence guarantee. The proposed variant is compared with the existing state-of-the-art approaches in the constrained BO literature via implementing these approaches on six different problems, including black-box, classical engineering, and hyperparameter tuning problems. Further, we demonstrate the effectiveness of our approach through graphical and statistical testing.},
	language = {en},
	number = {4},
	urldate = {2025-02-15},
	journal = {Technometrics},
	author = {Upadhye, Neelesh S. and Chowdhury, Raju},
	month = oct,
	year = {2024},
	pages = {561--574},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\FQWFUIPG\\Upadhye and Chowdhury - 2024 - Constrained Bayesian Optimization with Lower Confidence Bound.pdf:application/pdf},
}

@misc{wang_constrained_2024,
	title = {Constrained {Bayesian} optimization with merit functions},
	url = {http://arxiv.org/abs/2403.13140},
	doi = {10.48550/arXiv.2403.13140},
	abstract = {Bayesian optimization is a powerful optimization tool for problems where native first-order derivatives are unavailable. Recently, constrained Bayesian optimization (CBO) has been applied to many engineering applications where constraints are essential. However, several obstacles remain with current CBO algorithms that could prevent a wider adoption. We propose CBO algorithms using merit functions, such as the penalty merit function, in acquisition functions, inspired by nonlinear optimization methods, e.g., sequential quadratic programming. Merit functions measure the potential progress of both the objective and constraint functions, thus increasing algorithmic efficiency and allowing infeasible initial samples. The acquisition functions with merit functions are relaxed to have closed forms, making its implementation readily available wherever Bayesian optimization is. We further propose a unified CBO algorithm that can be seen as extension to the popular expected constrained improvement (ECI) approach. We demonstrate the effectiveness and efficiency of the proposed algorithms through numerical experiments on synthetic problems and a practical data-driven engineering design problem in the field of plasma physics.},
	language = {en},
	urldate = {2025-02-15},
	publisher = {arXiv},
	author = {Wang, J. and Petra, C. G. and Peterson, J. L.},
	month = mar,
	year = {2024},
	note = {arXiv:2403.13140 [math]},
	keywords = {Mathematics - Optimization and Control},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\TDFH6I4P\\Wang et al. - 2024 - Constrained Bayesian optimization with merit functions.pdf:application/pdf},
}

@misc{unknown_wave_2019,
	title = {Wave {Energy} {Converters}},
	url = {https://archive.ics.uci.edu/dataset/534},
	doi = {10.24432/C5QS4V},
	abstract = {Optimizing objectives under constraints, where both the objectives and constraints are black box functions, is common in real-world applications such as medical therapy design, industrial process optimization, and hyperparameter optimization. Bayesian Optimization (BO) is a popular approach for tackling these complex scenarios. However, constrained Bayesian Optimization (CBO) often relies on heuristics, approximations, or relaxation of objectives, leading to weaker theoretical guarantees compared to canonical BO. In this paper, we address this gap by focusing on identifying the interior optimum of the constrained objective, deliberately excluding boundary candidates susceptible to noise perturbations. Our approach leverages the insight that jointly optimizing the objective and learning the constraints can help pinpoint high-confidence regions of interest (ROI) likely to contain the interior optimum. We introduce an efficient CBO framework, which intersects these ROIs within a discretized search space to determine a general ROI. Within this ROI, we optimize the acquisition functions, balancing the learning of the constraints and the optimization of the objective. We showcase the efficiency and robustness of our proposed CBO framework through the high probability regret bounds for the algorithm and extensive empirical validation.},
	language = {en},
	urldate = {2025-02-15},
	publisher = {UCI Machine Learning Repository},
	author = {{Unknown}},
	year = {2019},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\EIY2ZWLG\\Unknown - 2019 - Wave Energy Converters.pdf:application/pdf},
}

@article{li_constrained_nodate,
	title = {Constrained {Multi}-{Objective} {Bayesian} {Optimization}},
	abstract = {Multi-objective Bayesian optimization has been widely adopted in scientific experiment design, including drug discovery and hyperparameter optimization. In practice, regulatory or safety concerns often impose additional thresholds on certain attributes of the experimental outcomes. Previous work has primarily focused on constrained single-objective optimization tasks or active search under constraints. We propose CMOBO, a sample-efficient constrained multi-objective Bayesian optimization algorithm that balances learning of the feasible region (defined on multiple unknowns) with multi-objective optimization within the feasible region in a principled manner. We provide both theoretical justification and empirical evidence, demonstrating the efficacy of our approach on various synthetic benchmarks and real-world applications.},
	language = {en},
	author = {Li, Diantong and Zhang, Fengxue and Liu, Chong and Chen, Yuxin},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\SPG7EHQ3\\Li et al. - Constrained Multi-Objective Bayesian Optimization.pdf:application/pdf},
}

@misc{franceschi_hyperparameter_2024,
	title = {Hyperparameter {Optimization} in {Machine} {Learning}},
	url = {http://arxiv.org/abs/2410.22854},
	doi = {10.48550/arXiv.2410.22854},
	abstract = {Hyperparameters are configuration variables controlling the behavior of machine learning algorithms. They are ubiquitous in machine learning and artificial intelligence and the choice of their values determine the effectiveness of systems based on these technologies. Manual hyperparameter search is often unsatisfactory and becomes unfeasible when the number of hyperparameters is large. Automating the search is an important step towards automating machine learning, freeing researchers and practitioners alike from the burden of finding a good set of hyperparameters by trial and error. In this survey, we present a unified treatment of hyperparameter optimization, providing the reader with examples and insights into the state-of-the-art. We cover the main families of techniques to automate hyperparameter search, often referred to as hyperparameter optimization or tuning, including random and quasi-random search, bandit-, model- and gradient- based approaches. We further discuss extensions, including online, constrained, and multi-objective formulations, touch upon connections with other fields such as meta-learning and neural architecture search, and conclude with open questions and future research directions.},
	language = {en},
	urldate = {2025-02-15},
	publisher = {arXiv},
	author = {Franceschi, Luca and Donini, Michele and Perrone, Valerio and Klein, Aaron and Archambeau, Cédric and Seeger, Matthias and Pontil, Massimiliano and Frasconi, Paolo},
	month = oct,
	year = {2024},
	note = {arXiv:2410.22854 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Preprint},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\TLRI73UN\\Franceschi et al. - 2024 - Hyperparameter Optimization in Machine Learning.pdf:application/pdf},
}

@misc{li_constrained_2024,
	title = {Constrained {Multi}-objective {Bayesian} {Optimization} through {Optimistic} {Constraints} {Estimation}},
	url = {http://arxiv.org/abs/2411.03641},
	doi = {10.48550/arXiv.2411.03641},
	abstract = {Multi-objective Bayesian optimization has been widely adopted in scientific experiment design, including drug discovery and hyperparameter optimization. In practice, regulatory or safety concerns often impose additional thresholds on certain attributes of the experimental outcomes. Previous work has primarily focused on constrained single-objective optimization tasks or active search under constraints. The existing constrained multi-objective algorithms address the issue with heuristics and approximations, posing challenges to the analysis of the sample efficiency. We propose a novel constrained multi-objective Bayesian optimization algorithm (CMOBO) that balances active learning of the level-set defined on multiple unknowns with multi-objective optimization within the feasible region. We provide both theoretical analysis and empirical evidence, demonstrating the efficacy of our approach on various synthetic benchmarks and real-world applications.},
	language = {en},
	urldate = {2025-02-15},
	publisher = {arXiv},
	author = {Li, Diantong and Zhang, Fengxue and Liu, Chong and Chen, Yuxin},
	month = nov,
	year = {2024},
	note = {arXiv:2411.03641 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Methodology},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\CE7P8FB5\\Li et al. - 2024 - Constrained Multi-objective Bayesian Optimization through Optimistic Constraints Estimation.pdf:application/pdf},
}

@misc{noauthor_mnist_2024,
	title = {{MNIST} database},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/wiki/MNIST_database},
	abstract = {The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning. It was created by "re-mixing" the samples from NIST's original datasets. The creators felt that since NIST's training dataset was taken from American Census Bureau employees, while the testing dataset was taken from American high school students, it was not well-suited for machine learning experiments. Furthermore, the black and white images from NIST were normalized to fit into a 28x28 pixel bounding box and anti-aliased, which introduced grayscale levels.
The MNIST database contains 60,000 training images and 10,000 testing images. Half of the training set and half of the test set were taken from NIST's training dataset, while the other half of the training set and the other half of the test set were taken from NIST's testing dataset. The original creators of the database keep a list of some of the methods tested on it. In their original paper, they use a support-vector machine to get an error rate of 0.8\%.
The original MNIST dataset contains at least 4 wrong labels.},
	language = {en},
	urldate = {2025-02-16},
	journal = {Wikipedia},
	month = dec,
	year = {2024},
	note = {Page Version ID: 1262526473},
	file = {Snapshot:C\:\\Users\\Gil\\Zotero\\storage\\X8DLMTGF\\MNIST_database.html:text/html},
}

@misc{nguyen_huu_tiep_lattice-physics_2024,
	title = {Lattice-physics ({PWR} fuel assembly neutronics simulation results)},
	url = {https://archive.ics.uci.edu/dataset/1091},
	doi = {10.24432/C5BK64},
	urldate = {2025-02-16},
	publisher = {UCI Machine Learning Repository},
	author = {{Nguyen Huu Tiep}},
	year = {2024},
}

@misc{unknown_ai4i_2020,
	title = {{AI4I} 2020 {Predictive} {Maintenance} {Dataset}},
	url = {https://archive.ics.uci.edu/dataset/601},
	doi = {10.24432/C5HS5C},
	urldate = {2025-02-16},
	publisher = {UCI Machine Learning Repository},
	author = {{Unknown}},
	year = {2020},
}

@misc{paulo_cortez_wine_2009,
	title = {Wine {Quality}},
	url = {https://archive.ics.uci.edu/dataset/186},
	doi = {10.24432/C56S3T},
	urldate = {2025-02-16},
	publisher = {UCI Machine Learning Repository},
	author = {Paulo Cortez, A. Cerdeira},
	year = {2009},
}

@misc{hernandez-lobato_predictive_2015,
	title = {Predictive {Entropy} {Search} for {Bayesian} {Optimization} with {Unknown} {Constraints}},
	url = {http://arxiv.org/abs/1502.05312},
	doi = {10.48550/arXiv.1502.05312},
	abstract = {Unknown constraints arise in many types of expensive black-box optimization problems. Several methods have been proposed recently for performing Bayesian optimization with constraints, based on the expected improvement (EI) heuristic. However, EI can lead to pathologies when used with constraints. For example, in the case of decoupled constraints—i.e., when one can independently evaluate the objective or the constraints—EI can encounter a pathology that prevents exploration. Additionally, computing EI requires a current best solution, which may not exist if none of the data collected so far satisfy the constraints. By contrast, informationbased approaches do not suffer from these failure modes. In this paper, we present a new information-based method called Predictive Entropy Search with Constraints (PESC). We analyze the performance of PESC and show that it compares favorably to EI-based approaches on synthetic and benchmark problems, as well as several real-world examples. We demonstrate that PESC is an effective algorithm that provides a promising direction towards a uniﬁed solution for constrained Bayesian optimization.},
	language = {en},
	urldate = {2025-02-17},
	publisher = {arXiv},
	author = {Hernández-Lobato, José Miguel and Gelbart, Michael A. and Hoffman, Matthew W. and Adams, Ryan P. and Ghahramani, Zoubin},
	month = jul,
	year = {2015},
	note = {arXiv:1502.05312 [stat]},
	keywords = {Statistics - Machine Learning},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\7RQAMLGA\\Hernández-Lobato et al. - 2015 - Predictive Entropy Search for Bayesian Optimization with Unknown Constraints.pdf:application/pdf},
}

@misc{brochu_portfolio_2011,
	title = {Portfolio {Allocation} for {Bayesian} {Optimization}},
	url = {http://arxiv.org/abs/1009.5419},
	doi = {10.48550/arXiv.1009.5419},
	abstract = {Bayesian optimization with Gaussian processes has become an increasingly popular tool in the machine learning community. It is eﬃcient and can be used when very little is known about the objective function, making it popular in expensive black-box optimization scenarios. It is able to do this by sampling the objective using an acquisition function which incorporates the model’s estimate of the objective and the uncertainty at any given point. However, there are several diﬀerent parameterized acquisition functions in the literature, and it is often unclear which one to use. Instead of using a single acquisition function, we adopt a portfolio of acquisition functions governed by an online multi-armed bandit strategy. We describe the method, which we call GP-Hedge, and show that this method almost always outperforms the best individual acquisition function.},
	language = {en},
	urldate = {2025-02-17},
	publisher = {arXiv},
	author = {Brochu, Eric and Hoffman, Matthew W. and Freitas, Nando de},
	month = mar,
	year = {2011},
	note = {arXiv:1009.5419 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: This revision contains an updated the performance bound and other minor text changes},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\69MFDFDV\\Brochu et al. - 2011 - Portfolio Allocation for Bayesian Optimization.pdf:application/pdf},
}

@article{srinivas_gaussian_2012,
	title = {Gaussian {Process} {Optimization} in the {Bandit} {Setting}: {No} {Regret} and {Experimental} {Design}},
	volume = {58},
	issn = {0018-9448, 1557-9654},
	shorttitle = {Gaussian {Process} {Optimization} in the {Bandit} {Setting}},
	url = {http://arxiv.org/abs/0912.3995},
	doi = {10.1109/TIT.2011.2182033},
	abstract = {Many applications require optimizing an unknown, noisy function that is expensive to evaluate. We formalize this task as a multiarmed bandit problem, where the payoﬀ function is either sampled from a Gaussian process (GP) or has low RKHS norm. We resolve the important open problem of deriving regret bounds for this setting, which imply novel convergence rates for GP optimization. We analyze GP-UCB, an intuitive upper-conﬁdence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design. Moreover, by bounding the latter in terms of operator spectra, we obtain explicit sublinear regret bounds for many commonly used covariance functions. In some important cases, our bounds have surprisingly weak dependence on the dimensionality. In our experiments on real sensor data, GP-UCB compares favorably with other heuristical GP optimization approaches.},
	language = {en},
	number = {5},
	urldate = {2025-02-17},
	journal = {IEEE Transactions on Information Theory},
	author = {Srinivas, Niranjan and Krause, Andreas and Kakade, Sham M. and Seeger, Matthias},
	month = may,
	year = {2012},
	note = {arXiv:0912.3995 [cs]},
	keywords = {Computer Science - Machine Learning},
	pages = {3250--3265},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\7EBTG6JF\\Srinivas et al. - 2012 - Gaussian Process Optimization in the Bandit Setting No Regret and Experimental Design.pdf:application/pdf},
}

@misc{ortega_minimum_2010,
	title = {A {Minimum} {Relative} {Entropy} {Principle} for {Learning} and {Acting}},
	url = {http://arxiv.org/abs/0810.3605},
	doi = {10.48550/arXiv.0810.3605},
	abstract = {This paper proposes a method to construct an adaptive agent that is universal with respect to a given class of experts, where each expert is an agent that has been designed speciﬁcally for a particular environment. This adaptive control problem is formalized as the problem of minimizing the relative entropy of the adaptive agent from the expert that is most suitable for the unknown environment. If the agent is a passive observer, then the optimal solution is the well-known Bayesian predictor. However, if the agent is active, then its past actions need to be treated as causal interventions on the I/O stream rather than normal probability conditions. Here it is shown that the solution to this new variational problem is given by a stochastic controller called the Bayesian control rule, which implements adaptive behavior as a mixture of experts. Furthermore, it is shown that under mild assumptions, the Bayesian control rule converges to the control law of the most suitable expert.},
	language = {en},
	urldate = {2025-02-17},
	publisher = {arXiv},
	author = {Ortega, Pedro A. and Braun, Daniel A.},
	month = apr,
	year = {2010},
	note = {arXiv:0810.3605 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: 36 pages, 11 figures},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\54WWE6BB\\Ortega and Braun - 2010 - A Minimum Relative Entropy Principle for Learning and Acting.pdf:application/pdf},
}

@misc{hernandez-lobato_predictive_2014,
	title = {Predictive {Entropy} {Search} for {Efficient} {Global} {Optimization} of {Black}-box {Functions}},
	url = {http://arxiv.org/abs/1406.2541},
	doi = {10.48550/arXiv.1406.2541},
	abstract = {We propose a novel information-theoretic approach for Bayesian optimization called Predictive Entropy Search (PES). At each iteration, PES selects the next evaluation point that maximizes the expected information gained with respect to the global maximum. PES codiﬁes this intractable acquisition function in terms of the expected reduction in the differential entropy of the predictive distribution. This reformulation allows PES to obtain approximations that are both more accurate and efﬁcient than other alternatives such as Entropy Search (ES). Furthermore, PES can easily perform a fully Bayesian treatment of the model hyperparameters while ES cannot. We evaluate PES in both synthetic and realworld applications, including optimization problems in machine learning, ﬁnance, biotechnology, and robotics. We show that the increased accuracy of PES leads to signiﬁcant gains in optimization performance.},
	language = {en},
	urldate = {2025-02-17},
	publisher = {arXiv},
	author = {Hernández-Lobato, José Miguel and Hoffman, Matthew W. and Ghahramani, Zoubin},
	month = jun,
	year = {2014},
	note = {arXiv:1406.2541 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\G6BFV8NW\\Hernández-Lobato et al. - 2014 - Predictive Entropy Search for Efficient Global Optimization of Black-box Functions.pdf:application/pdf},
}

@misc{i-cheng_yeh_concrete_1998,
	title = {Concrete {Compressive} {Strength}},
	url = {https://archive.ics.uci.edu/dataset/165},
	doi = {10.24432/C5PK67},
	urldate = {2025-02-17},
	publisher = {UCI Machine Learning Repository},
	author = {{I-Cheng Yeh}},
	year = {1998},
}

@article{yeh_modeling_1998,
	title = {Modeling of strength of high-performance concrete using artificial neural networks},
	volume = {28},
	issn = {0008-8846},
	url = {https://www.sciencedirect.com/science/article/pii/S0008884698001653},
	doi = {10.1016/S0008-8846(98)00165-3},
	abstract = {Several studies independently have shown that concrete strength development is determined not only by the water-to-cement ratio, but that it also is influenced by the content of other concrete ingredients. High-performance concrete is a highly complex material, which makes modeling its behavior a very difficult task. This paper is aimed at demonstrating the possibilities of adapting artificial neural networks (ANN) to predict the compressive strength of high-performance concrete. A set of trial batches of HPC was produced in the laboratory and demonstrated satisfactory experimental results. This study led to the following conclusions: 1) A strength model based on ANN is more accurate than a model based on regression analysis; and 2) It is convenient and easy to use ANN models for numerical experiments to review the effects of the proportions of each variable on the concrete mix.},
	number = {12},
	urldate = {2025-02-17},
	journal = {Cement and Concrete Research},
	author = {Yeh, I. -C.},
	month = dec,
	year = {1998},
	pages = {1797--1808},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\VR53MIDJ\\Yeh - 1998 - Modeling of strength of high-performance concrete using artificial neural networks.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Gil\\Zotero\\storage\\448JKT2S\\S0008884698001653.html:text/html},
}

@inproceedings{matzka_explainable_2020,
	address = {Irvine, CA, USA},
	title = {Explainable {Artificial} {Intelligence} for {Predictive} {Maintenance} {Applications}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-7281-8701-3},
	url = {https://ieeexplore.ieee.org/document/9253083/},
	doi = {10.1109/AI4I49448.2020.00023},
	abstract = {This paper presents and provides a realistic, yet synthetic, predictive maintenance dataset for use in this paper and by the community. An explainable model and an explanatory interface are described, trained using the dataset, and their explanatory performance evaluated and compared.},
	language = {en},
	urldate = {2025-02-18},
	booktitle = {2020 {Third} {International} {Conference} on {Artificial} {Intelligence} for {Industries} ({AI4I})},
	publisher = {IEEE},
	author = {Matzka, Stephan},
	month = sep,
	year = {2020},
	pages = {69--74},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\X4Q38989\\Matzka - 2020 - Explainable Artificial Intelligence for Predictive Maintenance Applications.pdf:application/pdf},
}

@misc{fan_hyperbo_2023,
	title = {{HyperBO}+: {Pre}-training a universal prior for {Bayesian} optimization with hierarchical {Gaussian} processes},
	shorttitle = {{HyperBO}+},
	url = {http://arxiv.org/abs/2212.10538},
	doi = {10.48550/arXiv.2212.10538},
	abstract = {Bayesian optimization (BO), while proved highly effective for many black-box function optimization tasks, requires practitioners to carefully select priors that well model their functions of interest. Rather than specifying by hand, researchers have investigated transfer learning based methods to automatically learn the priors, e.g. multi-task BO (Swersky et al., 2013), few-shot BO (Wistuba and Grabocka, 2021) and HyperBO (Wang et al., 2022). However, those prior learning methods typically assume that the input domains are the same for all tasks, weakening their ability to use observations on functions with different domains or generalize the learned priors to BO on different search spaces. In this work, we present HyperBO+: a pre-training approach for hierarchical Gaussian processes that enables the same prior to work universally for Bayesian optimization on functions with different domains. We propose a two-step pre-training method and analyze its appealing asymptotic properties and benefits to BO both theoretically and empirically. On real-world hyperparameter tuning tasks that involve multiple search spaces, we demonstrate that HyperBO+ is able to generalize to unseen search spaces and achieves lower regrets than competitive baselines.},
	language = {en},
	urldate = {2025-02-19},
	publisher = {arXiv},
	author = {Fan, Zhou and Han, Xinran and Wang, Zi},
	month = sep,
	year = {2023},
	note = {arXiv:2212.10538 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Full version of the workshop paper at 2022 NeurIPS Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\ZQ6RU24S\\Fan et al. - 2023 - HyperBO+ Pre-training a universal prior for Bayesian optimization with hierarchical Gaussian proces.pdf:application/pdf},
}

@article{wang_pre-trained_2024,
	title = {Pre-trained {Gaussian} {Processes} for {Bayesian} {Optimization}},
	volume = {25},
	url = {http://jmlr.org/papers/v25/23-0269.html},
	abstract = {Bayesian optimization (BO) has become a popular strategy for global optimization of expensive real-world functions. Contrary to a common expectation that BO is suited to optimizing black-box functions, it actually requires domain knowledge about those functions to deploy BO successfully. Such domain knowledge often manifests in Gaussian process (GP) priors that specify initial beliefs on functions. However, even with expert knowledge, it is non-trivial to quantitatively deﬁne a prior. This is especially true for hyperparameter tuning problems on complex machine learning models, where landscapes of tuning objectives are often difﬁcult to comprehend. We seek an alternative practice for setting these functional priors. In particular, we consider the scenario where we have data from similar functions that allow us to pre-train a tighter distribution a priori. We detail what pretraining entails for GPs using a KL divergence based loss function, and propose a new pre-training based BO framework named HyperBO. Theoretically, we show bounded posterior predictions and near-zero regrets for HyperBO without assuming the “ground truth” GP prior is known. To verify our approach in realistic setups, we collect a large multi-task hyperparameter tuning dataset by training tens of thousands of conﬁgurations of near-state-of-the-art deep learning models on popular image and text datasets, as well as a protein sequence dataset. Our results show that on average, HyperBO is able to locate good hyperparameters at least 3 times more efﬁciently than the best competing methods on both our new tuning dataset and existing multi-task BO benchmarks.},
	language = {en},
	number = {212},
	journal = {Journal of Machine Learning Research},
	author = {Wang, Zi and Dahl, George E and Swersky, Kevin and Lee, Chansoo and Nado, Zachary and Gilmer, Justin and Snoek, Jasper and Ghahramani, Zoubin},
	year = {2024},
	pages = {1--83},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\MV599ZQA\\Wang et al. - Pre-trained Gaussian Processes for Bayesian Optimization.pdf:application/pdf},
}

@misc{paszke_pytorch_2019,
	title = {{PyTorch}: {An} {Imperative} {Style}, {High}-{Performance} {Deep} {Learning} {Library}},
	shorttitle = {{PyTorch}},
	url = {http://arxiv.org/abs/1912.01703},
	doi = {10.48550/arXiv.1912.01703},
	abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientiﬁc computing libraries, while remaining efﬁcient and supporting hardware accelerators such as GPUs.},
	language = {en},
	urldate = {2025-02-19},
	publisher = {arXiv},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Köpf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	month = dec,
	year = {2019},
	note = {arXiv:1912.01703 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Mathematical Software},
	annote = {Comment: 12 pages, 3 figures, NeurIPS 2019},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\CPQW2IUL\\Paszke et al. - 2019 - PyTorch An Imperative Style, High-Performance Deep Learning Library.pdf:application/pdf},
}

@misc{kernc_sambo_2024,
	title = {{SAMBO}: {Sequential} and {Model}-{Based} {Optimization}: {Efficient} global optimization in {Python}},
	url = {https://sambo-optimization.github.io},
	author = {{Kernc}},
	year = {2024},
	doi = {https://doi.org/10.5281/zenodo.14461363},
}

@article{lindauer_smac3_nodate,
	title = {{SMAC3}: {A} {Versatile} {Bayesian} {Optimization} {Package} for {Hyperparameter} {Optimization}},
	abstract = {Algorithm parameters, in particular hyperparameters of machine learning algorithms, can substantially impact their performance. To support users in determining well-performing hyperparameter conﬁgurations for their algorithms, datasets and applications at hand, SMAC3 oﬀers a robust and ﬂexible framework for Bayesian Optimization, which can improve performance within a few evaluations. It oﬀers several facades and pre-sets for typical use cases, such as optimizing hyperparameters, solving low dimensional continuous (artiﬁcial) global optimization problems and conﬁguring algorithms to perform well across multiple problem instances. The SMAC3 package is available under a permissive BSD-license at https://github.com/automl/SMAC3.},
	language = {en},
	author = {Lindauer, Marius and Eggensperger, Katharina and Feurer, Matthias and Biedenkapp, Andre and Deng, Difan and Benjamins, Carolin and Ruhkopf, Tim and Sass, Rene and Hutter, Frank},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\I8J9AQKI\\Lindauer et al. - SMAC3 A Versatile Bayesian Optimization Package for Hyperparameter Optimization.pdf:application/pdf},
}

@misc{noauthor_ax_nodate,
	title = {Ax {\textbar} {Ax}},
	url = {https://ax.dev/},
	abstract = {Adaptive Experimentation Platform},
	language = {en},
	urldate = {2025-02-19},
	file = {Snapshot:C\:\\Users\\Gil\\Zotero\\storage\\M7H63EYR\\ax.dev.html:text/html},
}

@misc{noauthor_botorch_nodate,
	title = {{BoTorch} {\textbar} {BoTorch}},
	url = {https://botorch.org/},
	abstract = {Bayesian Optimization in PyTorch},
	language = {en},
	urldate = {2025-02-19},
	file = {Snapshot:C\:\\Users\\Gil\\Zotero\\storage\\Q8U5X48S\\botorch.org.html:text/html},
}

@misc{noauthor_pylopspyproximal_2025,
	title = {{PyLops}/pyproximal},
	copyright = {LGPL-3.0},
	url = {https://github.com/PyLops/pyproximal},
	abstract = {PyProximal – Proximal Operators and Algorithms in Python},
	urldate = {2025-02-22},
	publisher = {PyLops},
	month = feb,
	year = {2025},
	note = {original-date: 2021-01-06T16:56:06Z},
	keywords = {inverse-problems, linear-algebra, proximal-algorithms, python},
}

@misc{noauthor_pyproximal_nodate,
	title = {{PyProximal} — {PyProximal}},
	url = {https://pyproximal.readthedocs.io/en/stable/},
	urldate = {2025-02-22},
	file = {PyProximal — PyProximal:C\:\\Users\\Gil\\Zotero\\storage\\ALBCF79B\\stable.html:text/html},
}

@misc{wilson_deep_2015,
	title = {Deep {Kernel} {Learning}},
	url = {http://arxiv.org/abs/1511.02222},
	doi = {10.48550/arXiv.1511.02222},
	abstract = {We introduce scalable deep kernels, which combine the structural properties of deep learning architectures with the non-parametric ﬂexibility of kernel methods. Speciﬁcally, we transform the inputs of a spectral mixture base kernel with a deep architecture, using local kernel interpolation, inducing points, and structure exploiting (Kronecker and Toeplitz) algebra for a scalable kernel representation. These closed-form kernels can be used as drop-in replacements for standard kernels, with beneﬁts in expressive power and scalability. We jointly learn the properties of these kernels through the marginal likelihood of a Gaussian process. Inference and learning cost O(n) for n training points, and predictions cost O(1) per test point. On a large and diverse collection of applications, including a dataset with 2 million examples, we show improved performance over scalable Gaussian processes with ﬂexible kernel learning models, and stand-alone deep architectures.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P.},
	month = nov,
	year = {2015},
	note = {arXiv:1511.02222 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Methodology},
	annote = {Comment: 19 pages, 6 figures},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\5V5DVCIH\\Wilson et al. - 2015 - Deep Kernel Learning.pdf:application/pdf},
}

@misc{li_study_2024,
	title = {A {Study} of {Bayesian} {Neural} {Network} {Surrogates} for {Bayesian} {Optimization}},
	url = {http://arxiv.org/abs/2305.20028},
	doi = {10.48550/arXiv.2305.20028},
	abstract = {Bayesian optimization is a highly efficient approach to optimizing objective functions which are expensive to query. These objectives are typically represented by Gaussian process (GP) surrogate models which are easy to optimize and support exact inference. While standard GP surrogates have been well-established in Bayesian optimization, Bayesian neural networks (BNNs) have recently become practical function approximators, with many benefits over standard GPs such as the ability to naturally handle non-stationarity and learn representations for high-dimensional data. In this paper, we study BNNs as alternatives to standard GP surrogates for optimization. We consider a variety of approximate inference procedures for finitewidth BNNs, including high-quality Hamiltonian Monte Carlo, low-cost stochastic MCMC, and heuristics such as deep ensembles. We also consider infinite-width BNNs, linearized Laplace approximations, and partially stochastic models such as deep kernel learning. We evaluate this collection of surrogate models on diverse problems with varying dimensionality, number of objectives, non-stationarity, and discrete and continuous inputs. We find: (i) the ranking of methods is highly problem dependent, suggesting the need for tailored inductive biases; (ii) HMC is the most successful approximate inference procedure for fully stochastic BNNs; (iii) full stochasticity may be unnecessary as deep kernel learning is relatively competitive; (iv) deep ensembles perform relatively poorly; (v) infinite-width BNNs are particularly promising, especially in high dimensions.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Li, Yucen Lily and Rudner, Tim G. J. and Wilson, Andrew Gordon},
	month = may,
	year = {2024},
	note = {arXiv:2305.20028 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: ICLR 2024. Code available at https://github.com/yucenli/bnn-bo},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\34YYEAF4\\Li et al. - 2024 - A Study of Bayesian Neural Network Surrogates for Bayesian Optimization.pdf:application/pdf},
}

@misc{davies_random_2014,
	title = {The {Random} {Forest} {Kernel} and other kernels for big data from random partitions},
	url = {http://arxiv.org/abs/1402.4293},
	doi = {10.48550/arXiv.1402.4293},
	abstract = {We present Random Partition Kernels, a new class of kernels derived by demonstrating a natural connection between random partitions of objects and kernels between those objects. We show how the construction can be used to create kernels from methods that would not normally be viewed as random partitions, such as Random Forest. To demonstrate the potential of this method, we propose two new kernels, the Random Forest Kernel and the Fast Cluster Kernel, and show that these kernels consistently outperform standard kernels on problems involving real-world datasets. Finally, we show how the form of these kernels lend themselves to a natural approximation that is appropriate for certain big data problems, allowing O(N ) inference in methods such as Gaussian Processes, Support Vector Machines and Kernel PCA.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Davies, Alex and Ghahramani, Zoubin},
	month = feb,
	year = {2014},
	note = {arXiv:1402.4293 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\7DZKHTGS\\Davies and Ghahramani - 2014 - The Random Forest Kernel and other kernels for big data from random partitions.pdf:application/pdf},
}

@misc{white_neural_2023,
	title = {Neural {Architecture} {Search}: {Insights} from 1000 {Papers}},
	shorttitle = {Neural {Architecture} {Search}},
	url = {http://arxiv.org/abs/2301.08727},
	doi = {10.48550/arXiv.2301.08727},
	abstract = {In the past decade, advances in deep learning have resulted in breakthroughs in a variety of areas, including computer vision, natural language understanding, speech recognition, and reinforcement learning. Specialized, high-performing neural architectures are crucial to the success of deep learning in these areas. Neural architecture search (NAS), the process of automating the design of neural architectures for a given task, is an inevitable next step in automating machine learning and has already outpaced the best human-designed architectures on many tasks. In the past few years, research in NAS has been progressing rapidly, with over 1000 papers released since 2020 (Deng and Lindauer, 2021). In this survey, we provide an organized and comprehensive guide to neural architecture search. We give a taxonomy of search spaces, algorithms, and speedup techniques, and we discuss resources such as benchmarks, best practices, other surveys, and open-source libraries.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {White, Colin and Safari, Mahmoud and Sukthanker, Rhea and Ru, Binxin and Elsken, Thomas and Zela, Arber and Dey, Debadeepta and Hutter, Frank},
	month = jan,
	year = {2023},
	note = {arXiv:2301.08727 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\J6PGLUE8\\White et al. - 2023 - Neural Architecture Search Insights from 1000 Papers.pdf:application/pdf},
}

@misc{schrodi_construction_2023,
	title = {Construction of {Hierarchical} {Neural} {Architecture} {Search} {Spaces} based on {Context}-free {Grammars}},
	url = {http://arxiv.org/abs/2211.01842},
	doi = {10.48550/arXiv.2211.01842},
	abstract = {The discovery of neural architectures from simple building blocks is a longstanding goal of Neural Architecture Search (NAS). Hierarchical search spaces are a promising step towards this goal but lack a unifying search space design framework and typically only search over some limited aspect of architectures. In this work, we introduce a unifying search space design framework based on context-free grammars that can naturally and compactly generate expressive hierarchical search spaces that are 100s of orders of magnitude larger than common spaces from the literature. By enhancing and using their properties, we effectively enable search over the complete architecture and can foster regularity. Further, we propose an efficient hierarchical kernel design for a Bayesian Optimization search strategy to efficiently search over such huge spaces. We demonstrate the versatility of our search space design framework and show that our search strategy can be superior to existing NAS approaches. Code is available at https://github.com/automl/hierarchical\_nas\_construction.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Schrodi, Simon and Stoll, Danny and Ru, Binxin and Sukthanker, Rhea and Brox, Thomas and Hutter, Frank},
	month = dec,
	year = {2023},
	note = {arXiv:2211.01842 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	annote = {Comment: NeurIPS 2023},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\2IPXD5UZ\\Schrodi et al. - 2023 - Construction of Hierarchical Neural Architecture Search Spaces based on Context-free Grammars.pdf:application/pdf},
}

@misc{thebelt_tree_2022,
	title = {Tree ensemble kernels for {Bayesian} optimization with known constraints over mixed-feature spaces},
	url = {http://arxiv.org/abs/2207.00879},
	doi = {10.48550/arXiv.2207.00879},
	abstract = {Tree ensembles can be well-suited for black-box optimization tasks such as algorithm tuning and neural architecture search, as they achieve good predictive performance with little or no manual tuning, naturally handle discrete feature spaces, and are relatively insensitive to outliers in the training data. Two well-known challenges in using tree ensembles for black-box optimization are (i) effectively quantifying model uncertainty for exploration and (ii) optimizing over the piece-wise constant acquisition function. To address both points simultaneously, we propose using the kernel interpretation of tree ensembles as a Gaussian Process prior to obtain model variance estimates, and we develop a compatible optimization formulation for the acquisition function. The latter further allows us to seamlessly integrate known constraints to improve sampling efﬁciency by considering domain-knowledge in engineering settings and modeling search space symmetries, e.g., hierarchical relationships in neural architecture search. Our framework performs as well as state-of-the-art methods for unconstrained black-box optimization over continuous/discrete features and outperforms competing methods for problems combining mixed-variable feature spaces and known input constraints.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Thebelt, Alexander and Tsay, Calvin and Lee, Robert M. and Sudermann-Merx, Nathan and Walz, David and Shafei, Behrang and Misener, Ruth},
	month = dec,
	year = {2022},
	note = {arXiv:2207.00879 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control, Computer Science - Artificial Intelligence},
	annote = {Comment: 27 pages, 9 figures, 4 tables},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\8GK2VE3U\\Thebelt et al. - 2022 - Tree ensemble kernels for Bayesian optimization with known constraints over mixed-feature spaces.pdf:application/pdf},
}

@misc{ament_unexpected_2025,
	title = {Unexpected {Improvements} to {Expected} {Improvement} for {Bayesian} {Optimization}},
	url = {http://arxiv.org/abs/2310.20708},
	doi = {10.48550/arXiv.2310.20708},
	abstract = {Expected Improvement (EI) is arguably the most popular acquisition function in Bayesian optimization and has found countless successful applications, but its performance is often exceeded by that of more recent methods. Notably, EI and its variants, including for the parallel and multi-objective settings, are challenging to optimize because their acquisition values vanish numerically in many regions. This difficulty generally increases as the number of observations, dimensionality of the search space, or the number of constraints grow, resulting in performance that is inconsistent across the literature and most often sub-optimal. Herein, we propose LogEI, a new family of acquisition functions whose members either have identical or approximately equal optima as their canonical counterparts, but are substantially easier to optimize numerically. We demonstrate that numerical pathologies manifest themselves in “classic” analytic EI, Expected Hypervolume Improvement (EHVI), as well as their constrained, noisy, and parallel variants, and propose corresponding reformulations that remedy these pathologies. Our empirical results show that members of the LogEI family of acquisition functions substantially improve on the optimization performance of their canonical counterparts and surprisingly, are on par with or exceed the performance of recent state-of-the-art acquisition functions, highlighting the understated role of numerical optimization in the literature.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Ament, Sebastian and Daulton, Samuel and Eriksson, David and Balandat, Maximilian and Bakshy, Eytan},
	month = jan,
	year = {2025},
	note = {arXiv:2310.20708 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Numerical Analysis, Mathematics - Numerical Analysis},
	annote = {Comment: NeurIPS 2023 Spotlight (https://openreview.net/forum?id=QFgYOtOkDB)},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\5AUV7VQN\\Ament et al. - 2025 - Unexpected Improvements to Expected Improvement for Bayesian Optimization.pdf:application/pdf},
}

@article{malkomes_beyond_nodate,
	title = {Beyond the {Pareto} {Efficient} {Frontier}: {Constraint} {Active} {Search} for {Multiobjective} {Experimental} {Design}},
	abstract = {Many problems in engineering design and simulation require balancing competing objectives under the presence of uncertainty. Sample-efﬁcient multiobjective optimization methods focus on the objective function values in metric space and ignore the sampling behavior of the design conﬁgurations in parameter space. Consequently, they may provide little actionable insight on how to choose designs in the presence of metric uncertainty or limited precision when implementing a chosen design. We propose a new formulation that accounts for the importance of the parameter space and is thus more suitable for multiobjective design problems; instead of searching for the Paretoefﬁcient frontier, we solicit the desired minimum performance thresholds on all objectives to deﬁne regions of satisfaction. We introduce an active search algorithm called Expected Coverage Improvement (ECI) to efﬁciently discover the region of satisfaction and simultaneously sample diverse acceptable conﬁgurations. We demonstrate our algorithm on several design and simulation domains: mechanical design, additive manufacturing, medical monitoring, and plasma physics.},
	language = {en},
	author = {Malkomes, Gustavo and Cheng, Bolong and Lee, Eric Hans and McCourt, Michael},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\LPAKMJCB\\Malkomes et al. - Beyond the Pareto Efficient Frontier Constraint Active Search for Multiobjective Experimental Desig.pdf:application/pdf},
}

@article{sbester_parallel_2004,
	title = {A parallel updating scheme for approximating and optimizing high fidelity computer simulations},
	volume = {27},
	copyright = {http://www.springer.com/tdm},
	issn = {1615-147X, 1615-1488},
	url = {http://link.springer.com/10.1007/s00158-004-0397-9},
	doi = {10.1007/s00158-004-0397-9},
	abstract = {Approximation methods are often used to construct surrogate models, which can replace expensive computer simulations for the purposes of optimization. One of the most important aspects of such optimization techniques is the choice of model updating strategy. In this paper we employ parallel updates by searching an expected improvement surface generated from a radial basis function model. We look at optimization based on standard and gradient-enhanced models. Given Np processors, the best Np local maxima of the expected improvement surface are highlighted and further runs are performed on these designs. To test these ideas, simple analytic functions and a ﬁnite element model of a simple structure are analysed and various approaches compared.},
	language = {en},
	number = {5},
	urldate = {2025-03-04},
	journal = {Structural and Multidisciplinary Optimization},
	author = {S�bester, A. and Leary, S.J. and Keane, A.J.},
	month = jul,
	year = {2004},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\YGX7W6YJ\\S�bester et al. - 2004 - A parallel updating scheme for approximating and optimizing high fidelity computer simulations.pdf:application/pdf},
}

@article{huang_sequential_2006,
	title = {Sequential kriging optimization using multiple-fidelity evaluations},
	volume = {32},
	copyright = {http://www.springer.com/tdm},
	issn = {1615-147X, 1615-1488},
	url = {http://link.springer.com/10.1007/s00158-005-0587-0},
	doi = {10.1007/s00158-005-0587-0},
	abstract = {When cost per evaluation on a system of interest is high, surrogate systems can provide cheaper but lower-ﬁdelity information. In the proposed extension of the sequential kriging optimization method, surrogate systems are exploited to reduce the total evaluation cost. The method utilizes data on all systems to build a kriging metamodel that provides a global prediction of the objective function and a measure of prediction uncertainty. The location and ﬁdelity level of the next evaluation are selected by maximizing an augmented expected improvement function, which is connected with the evaluation costs. The proposed method was applied to test functions from the literature and a metal-forming process design problem via ﬁnite element simulations. The method manifests sensible search patterns, robust performance, and appreciable reduction in total evaluation cost as compared to the original method.},
	language = {en},
	number = {5},
	urldate = {2025-03-04},
	journal = {Structural and Multidisciplinary Optimization},
	author = {Huang, D. and Allen, T. T. and Notz, W. I. and Miller, R. A.},
	month = sep,
	year = {2006},
	pages = {369--382},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\V9UPQJNI\\Huang et al. - 2006 - Sequential kriging optimization using multiple-fidelity evaluations.pdf:application/pdf},
}

@article{klein_fast_2017,
	title = {Fast {Bayesian} hyperparameter optimization on large datasets},
	volume = {11},
	issn = {1935-7524},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-11/issue-2/Fast-Bayesian-hyperparameter-optimization-on-large-datasets/10.1214/17-EJS1335SI.full},
	doi = {10.1214/17-EJS1335SI},
	abstract = {Bayesian optimization has become a successful tool for optimizing the hyperparameters of machine learning algorithms, such as support vector machines or deep neural networks. Despite its success, for large datasets, training and validating a single conﬁguration often takes hours, days, or even weeks, which limits the achievable performance. To accelerate hyperparameter optimization, we propose a generative model for the validation error as a function of training set size, which is learned during the optimization process and allows exploration of preliminary conﬁgurations on small subsets, by extrapolating to the full dataset. We construct a Bayesian optimization procedure, dubbed Fabolas, which models loss and training time as a function of dataset size and automatically trades oﬀ high information gain about the global optimum against computational cost. Experiments optimizing support vector machines and deep neural networks show that Fabolas often ﬁnds high-quality solutions 10 to 100 times faster than other state-of-the-art Bayesian optimization methods or the recently proposed bandit strategy Hyperband.},
	language = {en},
	number = {2},
	urldate = {2025-03-04},
	journal = {Electronic Journal of Statistics},
	author = {Klein, Aaron and Falkner, Stefan and Bartels, Simon and Hennig, Philipp and Hutter, Frank},
	month = jan,
	year = {2017},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\ZRD5TP6H\\Klein et al. - 2017 - Fast Bayesian hyperparameter optimization on large datasets.pdf:application/pdf},
}

@book{lookman_information_2016,
	address = {Cham},
	series = {Springer {Series} in {Materials} {Science}},
	title = {Information {Science} for {Materials} {Discovery} and {Design}},
	volume = {225},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-319-23870-8 978-3-319-23871-5},
	url = {https://link.springer.com/10.1007/978-3-319-23871-5},
	language = {en},
	urldate = {2025-03-04},
	publisher = {Springer International Publishing},
	editor = {Lookman, Turab and Alexander, Francis J. and Rajan, Krishna},
	year = {2016},
	doi = {10.1007/978-3-319-23871-5},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\29Y3CDZA\\Lookman et al. - 2016 - Information Science for Materials Discovery and Design.pdf:application/pdf},
}

@article{zhang_bayesian_2020,
	title = {Bayesian {Optimization} for {Materials} {Design} with {Mixed} {Quantitative} and {Qualitative} {Variables}},
	volume = {10},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-60652-9},
	doi = {10.1038/s41598-020-60652-9},
	abstract = {Abstract
            Although Bayesian Optimization (BO) has been employed for accelerating materials design in computational materials engineering, existing works are restricted to problems with quantitative variables. However, real designs of materials systems involve both qualitative and quantitative design variables representing material compositions, microstructure morphology, and processing conditions. For mixed-variable problems, existing Bayesian Optimization (BO) approaches represent qualitative factors by dummy variables first and then fit a standard Gaussian process (GP) model with numerical variables as the surrogate model. This approach is restrictive theoretically and fails to capture complex correlations between qualitative levels. We present in this paper the integration of a novel latent-variable (LV) approach for mixed-variable GP modeling with the BO framework for materials design. LVGP is a fundamentally different approach that maps qualitative design variables to underlying numerical LV in GP, which has strong physical justification. It provides flexible parameterization and representation of qualitative factors and shows superior modeling accuracy compared to the existing methods. We demonstrate our approach through testing with numerical examples and materials design examples. The chosen materials design examples represent two different scenarios, one on concurrent materials selection and microstructure optimization for optimizing the light absorption of a quasi-random solar cell, and another on combinatorial search of material constitutes for optimal Hybrid Organic-Inorganic Perovskite (HOIP) design. It is found that in all test examples the mapped LVs provide intuitive visualization and substantial insight into the nature and effects of the qualitative factors. Though materials designs are used as examples, the method presented is generic and can be utilized for other mixed variable design optimization problems that involve expensive physics-based simulations.},
	language = {en},
	number = {1},
	urldate = {2025-03-04},
	journal = {Scientific Reports},
	author = {Zhang, Yichi and Apley, Daniel W. and Chen, Wei},
	month = mar,
	year = {2020},
	pages = {4924},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\7V3ZY7FB\\Zhang et al. - 2020 - Bayesian Optimization for Materials Design with Mixed Quantitative and Qualitative Variables.pdf:application/pdf},
}

@article{eriksson_high-dimensional_nodate,
	title = {High-{Dimensional} {Bayesian} {Optimization} with {Sparse} {Axis}-{Aligned} {Subspaces}},
	abstract = {Bayesian optimization (BO) is a powerful paradigm for efﬁcient optimization of black-box objective functions. High-dimensional BO presents a particular challenge, in part because the curse of dimensionality makes it difﬁcult to deﬁne—as well as do inference over—a suitable class of surrogate models. We argue that Gaussian process surrogate models deﬁned on sparse axis-aligned subspaces offer an attractive compromise between ﬂexibility and parsimony. We demonstrate that our approach, which relies on Hamiltonian Monte Carlo for inference, can rapidly identify sparse subspaces relevant to modeling the unknown objective function, enabling sample-efﬁcient high-dimensional BO. In an extensive suite of experiments comparing to existing methods for high-dimensional BO we demonstrate that our algorithm, Sparse AxisAligned Subspace BO (SAASBO), achieves excellent performance on several synthetic and realworld problems without the need to set problemspeciﬁc hyperparameters.},
	language = {en},
	author = {Eriksson, David and Jankowiak, Martin},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\23FQPH2Q\\Eriksson and Jankowiak - High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces.pdf:application/pdf},
}

@article{wang_bayesian_nodate,
	title = {Bayesian {Optimization} in {High} {Dimensions} via {Random} {Embeddings}},
	abstract = {Bayesian optimization techniques have been successfully applied to robotics, planning, sensor placement, recommendation, advertising, intelligent user interfaces and automatic algorithm conﬁguration. Despite these successes, the approach is restricted to problems of moderate dimension, and several workshops on Bayesian optimization have identiﬁed its scaling to high dimensions as one of the holy grails of the ﬁeld. In this paper, we introduce a novel random embedding idea to attack this problem. The resulting Random EMbedding Bayesian Optimization (REMBO) algorithm is very simple and applies to domains with both categorical and continuous variables. The experiments demonstrate that REMBO can effectively solve high-dimensional problems, including automatic parameter conﬁguration of a popular mixed integer linear programming solver.},
	language = {en},
	author = {Wang, Ziyu and Zoghi, Masrour and Hutter, Frank and Matheson, David},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\U9WI3XQ3\\Wang et al. - Bayesian Optimization in High Dimensions via Random Embeddings.pdf:application/pdf},
}

@misc{moriconi_high-dimensional_2020,
	title = {High-dimensional {Bayesian} optimization using low-dimensional feature spaces},
	url = {http://arxiv.org/abs/1902.10675},
	doi = {10.48550/arXiv.1902.10675},
	abstract = {Bayesian optimization (BO) is a powerful approach for seeking the global optimum of expensive black-box functions and has proven successful for ﬁne tuning hyper-parameters of machine learning models. However, BO is practically limited to optimizing 10–20 parameters. To scale BO to high dimensions, we usually make structural assumptions on the decomposition of the objective and/or exploit the intrinsic lower dimensionality of the problem, e.g. by using linear projections. We could achieve a higher compression rate with nonlinear projections, but learning these nonlinear embeddings typically requires much data. This contradicts the BO objective of a relatively small evaluation budget. To address this challenge, we propose to learn a low-dimensional feature space jointly with (a) the response surface and (b) a reconstruction mapping. Our approach allows for optimization of BO’s acquisition function in the lowerdimensional subspace, which signiﬁcantly simpliﬁes the optimization problem. We reconstruct the original parameter space from the lower-dimensional subspace for evaluating the black-box function. For meaningful exploration, we solve a constrained optimization problem1.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Moriconi, Riccardo and Deisenroth, Marc P. and Kumar, K. S. Sesh},
	month = sep,
	year = {2020},
	note = {arXiv:1902.10675 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\LV24PJIE\\Moriconi et al. - 2020 - High-dimensional Bayesian optimization using low-dimensional feature spaces.pdf:application/pdf},
}

@misc{papenmeier_understanding_2025,
	title = {Understanding {High}-{Dimensional} {Bayesian} {Optimization}},
	url = {http://arxiv.org/abs/2502.09198},
	doi = {10.48550/arXiv.2502.09198},
	abstract = {Recent work reported that simple Bayesian optimization methods perform well for highdimensional real-world tasks, seemingly contradicting prior work and tribal knowledge. This paper investigates the ‘why’. We identify fundamental challenges that arise in high-dimensional Bayesian optimization and explain why recent methods succeed. Our analysis shows that vanishing gradients caused by Gaussian process initialization schemes play a major role in the failures of high-dimensional Bayesian optimization and that methods that promote local search behaviors are better suited for the task. We find that maximum likelihood estimation of Gaussian process length scales suffices for state-of-the-art performance. Based on this, we propose a simple variant of maximum likelihood estimation called MSR that leverages these findings to achieve state-ofthe-art performance on a comprehensive set of real-world applications. We also present targeted experiments to illustrate and confirm our findings.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Papenmeier, Leonard and Poloczek, Matthias and Nardi, Luigi},
	month = feb,
	year = {2025},
	note = {arXiv:2502.09198 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: 19 pages, 20 figures},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\NTB9RZQB\\Papenmeier et al. - 2025 - Understanding High-Dimensional Bayesian Optimization.pdf:application/pdf},
}

@misc{wu_parallel_2018,
	title = {The {Parallel} {Knowledge} {Gradient} {Method} for {Batch} {Bayesian} {Optimization}},
	url = {http://arxiv.org/abs/1606.04414},
	doi = {10.48550/arXiv.1606.04414},
	abstract = {In many applications of black-box optimization, one can evaluate multiple points simultaneously, e.g. when evaluating the performances of several different neural networks in a parallel computing environment. In this paper, we develop a novel batch Bayesian optimization algorithm — the parallel knowledge gradient method. By construction, this method provides the one-step Bayes-optimal batch of points to sample. We provide an efﬁcient strategy for computing this Bayes-optimal batch of points, and we demonstrate that the parallel knowledge gradient method ﬁnds global optima signiﬁcantly faster than previous batch Bayesian optimization algorithms on both synthetic test functions and when tuning hyperparameters of practical machine learning algorithms, especially when function evaluations are noisy.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Wu, Jian and Frazier, Peter I.},
	month = apr,
	year = {2018},
	note = {arXiv:1606.04414 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: Minor edits and typo fixes. Please cite "J. Wu and P. Frazier. The parallel knowledge gradient method for batch bayesian optimization. In Advances In Neural Information Processing Systems, pp. 3126-3134. 2016"},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\7SP5GJYY\\Wu and Frazier - 2018 - The Parallel Knowledge Gradient Method for Batch Bayesian Optimization.pdf:application/pdf},
}

@misc{toscano-palmerin_bayesian_2018,
	title = {Bayesian {Optimization} with {Expensive} {Integrands}},
	url = {http://arxiv.org/abs/1803.08661},
	doi = {10.48550/arXiv.1803.08661},
	abstract = {We propose a Bayesian optimization algorithm for objective functions that are sums or integrals of expensive-to-evaluate functions, allowing noisy evaluations. These objective functions arise in multi-task Bayesian optimization for tuning machine learning hyperparameters, optimization via simulation, and sequential design of experiments with random environmental conditions. Our method is average-case optimal by construction when a single evaluation of the integrand remains within our evaluation budget. Achieving this one-step optimality requires solving a challenging value of information optimization problem, for which we provide a novel efﬁcient discretization-free computational method. We also provide consistency proofs for our method in both continuum and discrete ﬁnite domains for objective functions that are sums. In numerical experiments comparing against previous state-of-the-art methods, including those that also leverage sum or integral structure, our method performs as well or better across a wide range of problems and offers signiﬁcant improvements when evaluations are noisy or the integrand varies smoothly in the integrated variables.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Toscano-Palmerin, Saul and Frazier, Peter I.},
	month = mar,
	year = {2018},
	note = {arXiv:1803.08661 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\8DVDAH35\\Toscano-Palmerin and Frazier - 2018 - Bayesian Optimization with Expensive Integrands.pdf:application/pdf},
}

@misc{mcleod_practical_2018,
	title = {Practical {Bayesian} {Optimization} for {Variable} {Cost} {Objectives}},
	url = {http://arxiv.org/abs/1703.04335},
	doi = {10.48550/arXiv.1703.04335},
	abstract = {We propose a novel Bayesian Optimization approach for black-box objectives with a variable determining the tradeoff between evaluation cost and the ﬁdelity of the evaluations. Our approach chooses this variable at each step under an entropy-based acquisition function. Further, we use a new approach to sampling support points, which we show to provide a better approximation to the desired distribution and allow faster construction of the acquisition function. This allows us to achieve optimization with lower overheads than previous approaches; our approach is also implemented for a more general class of problem. We show this approach to be effective on synthetic and real-world benchmark problems.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {McLeod, Mark and Osborne, Michael A. and Roberts, Stephen J.},
	month = may,
	year = {2018},
	note = {arXiv:1703.04335 [stat]},
	keywords = {Statistics - Machine Learning},
	annote = {Comment: 8 pages, 7 figures},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\RNQP3BQ8\\McLeod et al. - 2018 - Practical Bayesian Optimization for Variable Cost Objectives.pdf:application/pdf},
}

@article{daulton_parallel_nodate,
	title = {Parallel {Bayesian} {Optimization} of {Multiple} {Noisy} {Objectives} with {Expected} {Hypervolume} {Improvement}},
	abstract = {Optimizing multiple competing black-box objectives is a challenging problem in many ﬁelds, including science, engineering, and machine learning. Multi-objective Bayesian optimization (MOBO) is a sample-efﬁcient approach for identifying the optimal trade-offs between the objectives. However, many existing methods perform poorly when the observations are corrupted by noise. We propose a novel acquisition function, NEHVI, that overcomes this important practical limitation by applying a Bayesian treatment to the popular expected hypervolume improvement (EHVI) criterion and integrating over this uncertainty in the Pareto frontier. We argue that, even in the noiseless setting, generating multiple candidates in parallel is an incarnation of EHVI with uncertainty in the Pareto frontier and therefore can be addressed using the same underlying technique. Through this lens, we derive a natural parallel variant, qNEHVI, that reduces computational complexity of parallel EHVI from exponential to polynomial with respect to the batch size. qNEHVI is one-step Bayes-optimal for hypervolume maximization in both noisy and noiseless environments, and we show that it can be optimized effectively with gradient-based methods via sample average approximation. Empirically, we demonstrate not only that qNEHVI is substantially more robust to observation noise than existing MOBO approaches, but also that it achieves state-of-the-art optimization performance and competitive wall-times in large-batch environments.},
	language = {en},
	author = {Daulton, Samuel and Balandat, Maximilian and Bakshy, Eytan},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\WYQX6MM6\\Daulton et al. - Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement.pdf:application/pdf},
}

@misc{poloczek_multi-information_2016,
	title = {Multi-{Information} {Source} {Optimization}},
	url = {http://arxiv.org/abs/1603.00389},
	doi = {10.48550/arXiv.1603.00389},
	abstract = {We consider Bayesian optimization of an expensive-to-evaluate black-box objective function, where we also have access to cheaper approximations of the objective. In general, such approximations arise in applications such as reinforcement learning, engineering, and the natural sciences, and are subject to an inherent, unknown bias. This model discrepancy is caused by an inadequate internal model that deviates from reality and can vary over the domain, making the utilization of these approximations a non-trivial task. We present a novel algorithm that provides a rigorous mathematical treatment of the uncertainties arising from model discrepancies and noisy observations. Its optimization decisions rely on a value of information analysis that extends the Knowledge Gradient factor to the setting of multiple information sources that vary in cost: each sampling decision maximizes the predicted benefit per unit cost. We conduct an experimental evaluation that demonstrates that the method consistently outperforms other state-of-the-art techniques: it finds designs of considerably higher objective value and additionally inflicts less cost in the exploration process.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Poloczek, Matthias and Wang, Jialei and Frazier, Peter I.},
	month = nov,
	year = {2016},
	note = {arXiv:1603.00389 [stat]},
	keywords = {Statistics - Machine Learning},
	annote = {Comment: Added: benchmark logistic regression on MNIST/USPS, comparison to MTBO/entropy search, estimation of hyper-parameters},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\GH9KWV5A\\Poloczek et al. - 2016 - Multi-Information Source Optimization.pdf:application/pdf},
}

@misc{wang_bayesian_2016,
	title = {Bayesian {Optimization} in a {Billion} {Dimensions} via {Random} {Embeddings}},
	url = {http://arxiv.org/abs/1301.1942},
	doi = {10.48550/arXiv.1301.1942},
	abstract = {Bayesian optimization techniques have been successfully applied to robotics, planning, sensor placement, recommendation, advertising, intelligent user interfaces and automatic algorithm conﬁguration. Despite these successes, the approach is restricted to problems of moderate dimension, and several workshops on Bayesian optimization have identiﬁed its scaling to high-dimensions as one of the holy grails of the ﬁeld. In this paper, we introduce a novel random embedding idea to attack this problem. The resulting Random EMbedding Bayesian Optimization (REMBO) algorithm is very simple, has important invariance properties, and applies to domains with both categorical and continuous variables. We present a thorough theoretical analysis of REMBO. Empirical results conﬁrm that REMBO can eﬀectively solve problems with billions of dimensions, provided the intrinsic dimensionality is low. They also show that REMBO achieves state-of-the-art performance in optimizing the 47 discrete parameters of a popular mixed integer linear programming solver.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Wang, Ziyu and Hutter, Frank and Zoghi, Masrour and Matheson, David and Freitas, Nando de},
	month = jan,
	year = {2016},
	note = {arXiv:1301.1942 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 33 pages},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\YZCX7MXU\\Wang et al. - 2016 - Bayesian Optimization in a Billion Dimensions via Random Embeddings.pdf:application/pdf},
}

@misc{kandasamy_high_2016,
	title = {High {Dimensional} {Bayesian} {Optimisation} and {Bandits} via {Additive} {Models}},
	url = {http://arxiv.org/abs/1503.01673},
	doi = {10.48550/arXiv.1503.01673},
	abstract = {Bayesian Optimisation (BO) is a technique used in optimising a D-dimensional function which is typically expensive to evaluate. While there have been many successes for BO in low dimensions, scaling it to high dimensions has been notoriously difﬁcult. Existing literature on the topic are under very restrictive settings. In this paper, we identify two key challenges in this endeavour. We tackle these challenges by assuming an additive structure for the function. This setting is substantially more expressive and contains a richer class of functions than previous work. We prove that, for additive functions the regret has only linear dependence on D even though the function depends on all D dimensions. We also demonstrate several other statistical and computational beneﬁts in our framework. Via synthetic examples, a scientiﬁc simulation and a face detection problem we demonstrate that our method outperforms naive BO on additive functions and on several examples where the function is not additive.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Kandasamy, Kirthevasan and Schneider, Jeff and Poczos, Barnabas},
	month = may,
	year = {2016},
	note = {arXiv:1503.01673 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Proceedings of The 32nd International Conference on Machine Learning 2015},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\TA6ISI64\\Kandasamy et al. - 2016 - High Dimensional Bayesian Optimisation and Bandits via Additive Models.pdf:application/pdf},
}

@article{daulton_hypervolume_nodate,
	title = {Hypervolume {Knowledge} {Gradient}: {A} {Lookahead} {Approach} for {Multi}-{Objective} {Bayesian} {Optimization} with {Partial} {Information}},
	abstract = {Bayesian optimization is a popular method for sample efficient multi-objective optimization. However, existing Bayesian optimization techniques fail to effectively exploit common and often-neglected problem structure such as decoupled evaluations, where objectives can be queried independently from one another and each may consume different resources, or multi-fidelity evaluations, where lower fidelity-proxies of the objectives can be evaluated at lower cost. In this work, we propose a general one-step lookahead acquisition function based on the Knowledge Gradient that addresses the complex question of what to evaluate when and at which design points in a principled Bayesian decision-theoretic fashion. Hence, our approach naturally addresses decoupled, multi-fidelity, and standard multi-objective optimization settings in a unified Bayesian decision making framework. By construction, our method is the one-step Bayes-optimal policy for hypervolume maximization. Empirically, we demonstrate that our method improves sample efficiency in a wide variety of synthetic and realworld problems. Furthermore, we show that our method is general-purpose and yields competitive performance in standard (potentially noisy) multi-objective optimization.},
	language = {en},
	author = {Daulton, Samuel and Balandat, Maximilian and Bakshy, Eytan},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\GD9RIFT6\\Daulton et al. - Hypervolume Knowledge Gradient A Lookahead Approach for Multi-Objective Bayesian Optimization with.pdf:application/pdf},
}

@article{pleiss_fast_nodate,
	title = {Fast {Matrix} {Square} {Roots} with {Applications} to {Gaussian} {Processes} and {Bayesian} {Optimization}},
	abstract = {Matrix square roots and their inverses arise frequently in machine learning, e.g., when sampling from high-dimensional Gaussians N (0, K) or “whitening” a vector b against covariance matrix K. While existing methods typically require O(N 3) computation, we introduce a highly-efﬁcient quadratic-time algorithm for computing K1/2b, K−1/2b, and their derivatives through matrix-vector multiplication (MVMs). Our method combines Krylov subspace methods with a rational approximation and typically achieves 4 decimal places of accuracy with fewer than 100 MVMs. Moreover, the backward pass requires little additional computation. We demonstrate our method’s applicability on matrices as large as 50,000 × 50,000—well beyond traditional methods—with little approximation error. Applying this increased scalability to variational Gaussian processes, Bayesian optimization, and Gibbs sampling results in more powerful models with higher accuracy. In particular, we perform variational GP inference with up to 10,000 inducing points and perform Gibbs sampling on a 25,000-dimensional problem.},
	language = {en},
	author = {Pleiss, Geoff and Jankowiak, Martin and Eriksson, David and Damle, Anil and Gardner, Jacob R},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\GLYYQN2H\\Pleiss et al. - Fast Matrix Square Roots with Applications to Gaussian Processes and Bayesian Optimization.pdf:application/pdf},
}

@article{swersky_multi-task_nodate,
	title = {Multi-{Task} {Bayesian} {Optimization}},
	abstract = {Bayesian optimization has recently been proposed as a framework for automatically tuning the hyperparameters of machine learning models and has been shown to yield state-of-the-art performance with impressive ease and efﬁciency. In this paper, we explore whether it is possible to transfer the knowledge gained from previous optimizations to new tasks in order to ﬁnd optimal hyperparameter settings more efﬁciently. Our approach is based on extending multi-task Gaussian processes to the framework of Bayesian optimization. We show that this method signiﬁcantly speeds up the optimization process when compared to the standard single-task approach. We further propose a straightforward extension of our algorithm in order to jointly minimize the average error across multiple tasks and demonstrate how this can be used to greatly speed up k-fold cross-validation. Lastly, we propose an adaptation of a recently developed acquisition function, entropy search, to the cost-sensitive, multi-task setting. We demonstrate the utility of this new acquisition function by leveraging a small dataset to explore hyperparameter settings for a large dataset. Our algorithm dynamically chooses which dataset to query in order to yield the most information per unit cost.},
	language = {en},
	author = {Swersky, Kevin and Snoek, Jasper and Adams, Ryan P},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\LEHDAW3C\\Swersky et al. - Multi-Task Bayesian Optimization.pdf:application/pdf},
}

@misc{wu_practical_2019,
	title = {Practical {Multi}-fidelity {Bayesian} {Optimization} for {Hyperparameter} {Tuning}},
	url = {http://arxiv.org/abs/1903.04703},
	doi = {10.48550/arXiv.1903.04703},
	abstract = {Bayesian optimization is popular for optimizing time-consuming black-box objectives. Nonetheless, for hyperparameter tuning in deep neural networks, the time required to evaluate the validation error for even a few hyperparameter settings remains a bottleneck. Multi-ﬁdelity optimization promises relief using cheaper proxies to such objectives — for example, validation error for a network trained using a subset of the training points or fewer iterations than required for convergence. We propose a highly ﬂexible and practical approach to multi-ﬁdelity Bayesian optimization, focused on efﬁciently optimizing hyperparameters for iteratively trained supervised learning models. We introduce a new acquisition function, the trace-aware knowledge-gradient, which efﬁciently leverages both multiple continuous ﬁdelity controls and trace observations — values of the objective at a sequence of ﬁdelities, available when varying ﬁdelity using training iterations. We provide a provably convergent method for optimizing our acquisition function and show it outperforms state-of-the-art alternatives for hyperparameter tuning of deep neural networks and large-scale kernel learning.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Wu, Jian and Toscano-Palmerin, Saul and Frazier, Peter I. and Wilson, Andrew Gordon},
	month = mar,
	year = {2019},
	note = {arXiv:1903.04703 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control, Statistics - Methodology},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\Y9WW9C8I\\Wu et al. - 2019 - Practical Multi-fidelity Bayesian Optimization for Hyperparameter Tuning.pdf:application/pdf},
}

@misc{feurer_practical_2022,
	title = {Practical {Transfer} {Learning} for {Bayesian} {Optimization}},
	url = {http://arxiv.org/abs/1802.02219},
	doi = {10.48550/arXiv.1802.02219},
	abstract = {When hyperparameter optimization of a machine learning algorithm is repeated for multiple datasets it is possible to transfer knowledge to an optimization run on a new dataset. We develop a new hyperparameter-free ensemble model for Bayesian optimization that is a generalization of two existing transfer learning extensions to Bayesian optimization and establish a worst-case bound compared to vanilla Bayesian optimization. Using a large collection of hyperparameter optimization benchmark problems, we demonstrate that our contributions substantially reduce optimization time compared to standard Gaussian process-based Bayesian optimization and improve over the current state-of-the-art for transfer hyperparameter optimization.},
	language = {en},
	urldate = {2025-03-04},
	publisher = {arXiv},
	author = {Feurer, Matthias and Letham, Benjamin and Hutter, Frank and Bakshy, Eytan},
	month = oct,
	year = {2022},
	note = {arXiv:1802.02219 [stat]},
	keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: This version fixes a minor error in the equation in Section 3.2 of V3},
	file = {PDF:C\:\\Users\\Gil\\Zotero\\storage\\VENGAZHA\\Feurer et al. - 2022 - Practical Transfer Learning for Bayesian Optimization.pdf:application/pdf},
}
